2025-08-31 01:05:35,684 - src.core.trainer - INFO - Logging setup complete. Log file: experiments/ppo_pendulum_mps_test_20250831_010535/logs/training.log
2025-08-31 01:05:35,685 - src.utils.registry - INFO - Registered algorithm: ppo -> PPOAlgorithm
2025-08-31 01:05:35,686 - src.utils.registry - INFO - Registered algorithm: random -> RandomAgent
2025-08-31 01:05:35,687 - src.utils.registry - INFO - Registered network: mlp -> MLP
2025-08-31 01:05:35,687 - src.utils.registry - INFO - Registered network: actor_mlp -> ActorMLP
2025-08-31 01:05:35,687 - src.utils.registry - INFO - Registered network: critic_mlp -> CriticMLP
2025-08-31 01:05:35,687 - src.utils.registry - INFO - Registered network: continuous_actor_mlp -> ContinuousActorMLP
2025-08-31 01:05:35,687 - src.utils.registry - INFO - Registered network: dueling_mlp -> DuelingMLP
2025-08-31 01:05:35,688 - src.utils.registry - INFO - Registered environment: gym -> GymWrapper
2025-08-31 01:05:35,689 - src.utils.registry - INFO - Registered buffer: trajectory -> TrajectoryBuffer
2025-08-31 01:05:35,689 - src.core.trainer - INFO - Initializing environment...
2025-08-31 01:05:35,735 - src.environments.gym_wrapper - INFO - Created Gym environment: Pendulum-v1
2025-08-31 01:05:35,735 - src.core.trainer - INFO - Environment: Pendulum-v1
2025-08-31 01:05:35,735 - src.core.trainer - INFO - Observation space: (3,)
2025-08-31 01:05:35,735 - src.core.trainer - INFO - Action space: (1,), discrete: False
2025-08-31 01:05:35,735 - src.core.trainer - INFO - Initializing networks...
2025-08-31 01:05:35,806 - src.core.trainer - INFO - Created actor network: continuous_actor_mlp
2025-08-31 01:05:35,808 - src.core.trainer - INFO - Created critic network: critic_mlp
2025-08-31 01:05:35,808 - src.core.trainer - INFO - Initializing algorithm...
2025-08-31 01:05:36,371 - src.core.trainer - INFO - Created algorithm: ppo
2025-08-31 01:05:36,372 - src.core.trainer - INFO - Initializing buffer...
2025-08-31 01:05:36,372 - src.core.trainer - INFO - Created buffer: trajectory
2025-08-31 01:05:36,374 - src.environments.gym_wrapper - INFO - Seed will be applied on next reset: 42
2025-08-31 01:05:36,374 - src.core.trainer - INFO - Random seeds set to 42
2025-08-31 01:05:36,374 - src.core.trainer - INFO - All components initialized successfully
2025-08-31 01:05:36,375 - src.utils.checkpoint - INFO - Checkpoint manager initialized at experiments/ppo_pendulum_mps_test_20250831_010535/checkpoints
2025-08-31 01:05:36,376 - src.utils.logger - INFO - TensorBoard logging enabled: experiments/ppo_pendulum_mps_test_20250831_010535/tensorboard
2025-08-31 01:05:36,376 - src.utils.logger - INFO - Experiment logger initialized: experiments/ppo_pendulum_mps_test_20250831_010535
2025-08-31 01:05:36,376 - src.utils.checkpoint - INFO - No checkpoint found to load
2025-08-31 01:05:36,376 - src.core.trainer - INFO - No checkpoint found, starting from scratch
2025-08-31 01:05:36,376 - src.core.trainer - INFO - Trainer initialized for experiment: ppo_pendulum_mps_test
2025-08-31 01:05:36,376 - src.core.trainer - INFO - Experiment directory: experiments/ppo_pendulum_mps_test_20250831_010535
2025-08-31 01:05:36,378 - src.utils.config - INFO - Configuration saved to experiments/ppo_pendulum_mps_test_20250831_010535/configs/config.yaml
2025-08-31 01:05:36,388 - src.core.trainer - INFO - Experiment config saved to experiments/ppo_pendulum_mps_test_20250831_010535/configs/config.yaml
2025-08-31 01:05:36,388 - __main__ - INFO - Experiment directory: experiments/ppo_pendulum_mps_test_20250831_010535
2025-08-31 01:05:36,388 - __main__ - INFO - Configuration hash: 4e710f52
2025-08-31 01:05:36,388 - __main__ - INFO - Starting training loop...
2025-08-31 01:05:36,388 - src.core.trainer - INFO - Starting training...
2025-08-31 01:05:36,388 - src.core.trainer - INFO - Target steps: 10000
2025-08-31 01:05:36,388 - src.core.trainer - INFO - Evaluation frequency: 5000
2025-08-31 01:05:36,388 - src.core.trainer - INFO - Checkpoint frequency: 10000
2025-08-31 01:06:10,947 - src.core.trainer - INFO - Running evaluation at step 10000
2025-08-31 01:06:12,289 - src.core.trainer - INFO - Evaluation complete - Mean return: -1542.45
2025-08-31 01:06:12,306 - src.utils.checkpoint - INFO - Checkpoint saved: experiments/ppo_pendulum_mps_test_20250831_010535/checkpoints/auto_step_10000.pt (step 10000)
2025-08-31 01:06:12,306 - src.core.trainer - INFO - Auto-saved checkpoint at step 10000
2025-08-31 01:06:12,306 - src.utils.logger - INFO - Step 10000 | train/policy_loss: 0.3379 | train/value_loss: 227449.8540 | train/entropy_loss: -0.0152 | train/total_loss: 159215.2330 | train/grad_norm: 1801.2585 | train/debug/update_mean_avg: 0.1299 | train/debug/update_mean_std: 0.2291 | train/debug/update_mean_min: -0.3528 | train/debug/update_mean_max: 0.3899 | train/debug/update_log_std_avg: -1.3916 | train/debug/update_std_avg: 0.2499 | train/debug/update_std_min: 0.1930 | train/debug/update_std_max: 0.2798 | train/debug/update_action_clipped_pct: 0.0000 | train/debug/update_network_output_shape: 2.0000 | train/debug/returns_mean: -430.8895 | train/debug/returns_std: 203.5232 | train/debug/returns_min: -819.1419 | train/debug/returns_max: -8.8511 | train/debug/advantages_mean: -0.0928 | train/debug/advantages_std: 1.0604 | train/debug/advantages_min: -1.4998 | train/debug/advantages_max: 3.6525 | train/debug/old_values_mean: -0.2590 | train/debug/old_values_std: 0.6511 | train/debug/value_error_mean: 430.6304 | train/time_elapsed: 35.9183 | train/steps_per_second: 278.4097
2025-08-31 01:06:12,308 - src.utils.logger - INFO - Step 10000 | eval/eval_step: 10000.0000 | eval/eval_episode_count: 5.0000 | eval/eval_return_mean: -1542.4475 | eval/eval_return_std: 213.2062 | eval/eval_return_min: -1790.5241 | eval/eval_return_max: -1259.9565 | eval/eval_length_mean: 200.0000
2025-08-31 01:06:12,309 - src.core.trainer - INFO - Training completed, running final evaluation...
2025-08-31 01:06:12,309 - src.core.trainer - INFO - Running evaluation at step 10000
2025-08-31 01:06:13,981 - src.core.trainer - INFO - Evaluation complete - Mean return: -1542.45
2025-08-31 01:06:14,011 - src.utils.checkpoint - INFO - Checkpoint saved: experiments/ppo_pendulum_mps_test_20250831_010535/checkpoints/final.pt (step 10000)
2025-08-31 01:06:14,011 - src.core.trainer - INFO - Final checkpoint saved: experiments/ppo_pendulum_mps_test_20250831_010535/checkpoints/final.pt
2025-08-31 01:06:14,011 - src.core.trainer - INFO - Training completed successfully in 37.6s
2025-08-31 01:06:14,024 - src.utils.logger - INFO - TensorBoard writer closed
2025-08-31 01:06:14,024 - __main__ - INFO - Training completed successfully!
2025-08-31 01:06:14,024 - __main__ - INFO - Final results:
2025-08-31 01:06:14,024 - __main__ - INFO -   final_step: 10000.0000
2025-08-31 01:06:14,024 - __main__ - INFO -   training_time: 37.6232
2025-08-31 01:06:14,024 - __main__ - INFO -   steps_per_second: 278.4097
2025-08-31 01:06:14,024 - __main__ - INFO -   policy_loss: 0.3379
2025-08-31 01:06:14,024 - __main__ - INFO -   value_loss: 227449.8540
2025-08-31 01:06:14,024 - __main__ - INFO -   entropy_loss: -0.0152
2025-08-31 01:06:14,024 - __main__ - INFO -   total_loss: 159215.2330
2025-08-31 01:06:14,024 - __main__ - INFO -   grad_norm: 1801.2585
2025-08-31 01:06:14,024 - __main__ - INFO -   debug/update_mean_avg: 0.1299
2025-08-31 01:06:14,024 - __main__ - INFO -   debug/update_mean_std: 0.2291
2025-08-31 01:06:14,024 - __main__ - INFO -   debug/update_mean_min: -0.3528
2025-08-31 01:06:14,024 - __main__ - INFO -   debug/update_mean_max: 0.3899
2025-08-31 01:06:14,024 - __main__ - INFO -   debug/update_log_std_avg: -1.3916
2025-08-31 01:06:14,024 - __main__ - INFO -   debug/update_std_avg: 0.2499
2025-08-31 01:06:14,024 - __main__ - INFO -   debug/update_std_min: 0.1930
2025-08-31 01:06:14,024 - __main__ - INFO -   debug/update_std_max: 0.2798
2025-08-31 01:06:14,024 - __main__ - INFO -   debug/update_action_clipped_pct: 0.0000
2025-08-31 01:06:14,024 - __main__ - INFO -   debug/update_network_output_shape: 2.0000
2025-08-31 01:06:14,024 - __main__ - INFO -   debug/returns_mean: -430.8895
2025-08-31 01:06:14,024 - __main__ - INFO -   debug/returns_std: 203.5232
2025-08-31 01:06:14,024 - __main__ - INFO -   debug/returns_min: -819.1419
2025-08-31 01:06:14,024 - __main__ - INFO -   debug/returns_max: -8.8511
2025-08-31 01:06:14,024 - __main__ - INFO -   debug/advantages_mean: -0.0928
2025-08-31 01:06:14,024 - __main__ - INFO -   debug/advantages_std: 1.0604
2025-08-31 01:06:14,024 - __main__ - INFO -   debug/advantages_min: -1.4998
2025-08-31 01:06:14,024 - __main__ - INFO -   debug/advantages_max: 3.6525
2025-08-31 01:06:14,024 - __main__ - INFO -   debug/old_values_mean: -0.2590
2025-08-31 01:06:14,024 - __main__ - INFO -   debug/old_values_std: 0.6511
2025-08-31 01:06:14,024 - __main__ - INFO -   debug/value_error_mean: 430.6304
2025-08-31 01:06:14,024 - __main__ - INFO -   eval_step: 10000.0000
2025-08-31 01:06:14,025 - __main__ - INFO -   eval_episode_count: 5.0000
2025-08-31 01:06:14,025 - __main__ - INFO -   eval_return_mean: -1542.4475
2025-08-31 01:06:14,025 - __main__ - INFO -   eval_return_std: 213.2062
2025-08-31 01:06:14,025 - __main__ - INFO -   eval_return_min: -1790.5241
2025-08-31 01:06:14,025 - __main__ - INFO -   eval_return_max: -1259.9565
2025-08-31 01:06:14,025 - __main__ - INFO -   eval_length_mean: 200.0000
2025-08-31 01:06:14,025 - __main__ - INFO -   time_elapsed: 35.9183
2025-08-31 01:06:14,025 - src.core.trainer - INFO - Trainer cleanup completed
