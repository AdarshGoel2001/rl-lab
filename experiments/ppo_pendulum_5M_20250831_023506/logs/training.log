2025-08-31 02:35:06,259 - src.core.trainer - INFO - Logging setup complete. Log file: experiments/ppo_pendulum_5M_20250831_023506/logs/training.log
2025-08-31 02:35:06,260 - src.utils.registry - INFO - Registered algorithm: ppo -> PPOAlgorithm
2025-08-31 02:35:06,261 - src.utils.registry - INFO - Registered algorithm: random -> RandomAgent
2025-08-31 02:35:06,261 - src.utils.registry - INFO - Registered network: mlp -> MLP
2025-08-31 02:35:06,261 - src.utils.registry - INFO - Registered network: actor_mlp -> ActorMLP
2025-08-31 02:35:06,261 - src.utils.registry - INFO - Registered network: critic_mlp -> CriticMLP
2025-08-31 02:35:06,261 - src.utils.registry - INFO - Registered network: continuous_actor_mlp -> ContinuousActorMLP
2025-08-31 02:35:06,262 - src.utils.registry - INFO - Registered network: dueling_mlp -> DuelingMLP
2025-08-31 02:35:06,263 - src.utils.registry - INFO - Registered environment: gym -> GymWrapper
2025-08-31 02:35:06,264 - src.utils.registry - INFO - Registered buffer: trajectory -> TrajectoryBuffer
2025-08-31 02:35:06,264 - src.core.trainer - INFO - Initializing environment...
2025-08-31 02:35:06,313 - src.environments.gym_wrapper - INFO - Created Gym environment: Pendulum-v1
2025-08-31 02:35:06,313 - src.core.trainer - INFO - Environment: Pendulum-v1
2025-08-31 02:35:06,313 - src.core.trainer - INFO - Observation space: (3,)
2025-08-31 02:35:06,314 - src.core.trainer - INFO - Action space: (1,), discrete: False
2025-08-31 02:35:06,314 - src.core.trainer - INFO - Initializing networks...
2025-08-31 02:35:06,357 - src.core.trainer - INFO - Created actor network: continuous_actor_mlp
2025-08-31 02:35:06,358 - src.core.trainer - INFO - Created critic network: critic_mlp
2025-08-31 02:35:06,358 - src.core.trainer - INFO - Initializing algorithm...
2025-08-31 02:35:06,938 - src.core.trainer - INFO - Created algorithm: ppo
2025-08-31 02:35:06,938 - src.core.trainer - INFO - Initializing buffer...
2025-08-31 02:35:06,938 - src.core.trainer - INFO - Created buffer: trajectory
2025-08-31 02:35:06,941 - src.environments.gym_wrapper - INFO - Seed will be applied on next reset: 42
2025-08-31 02:35:06,941 - src.core.trainer - INFO - Random seeds set to 42
2025-08-31 02:35:06,941 - src.core.trainer - INFO - All components initialized successfully
2025-08-31 02:35:06,941 - src.utils.checkpoint - INFO - Checkpoint manager initialized at experiments/ppo_pendulum_5M_20250831_023506/checkpoints
2025-08-31 02:35:06,942 - src.utils.logger - INFO - TensorBoard logging enabled: experiments/ppo_pendulum_5M_20250831_023506/tensorboard
2025-08-31 02:35:06,942 - src.utils.logger - INFO - Experiment logger initialized: experiments/ppo_pendulum_5M_20250831_023506
2025-08-31 02:35:06,943 - src.utils.checkpoint - INFO - No checkpoint found to load
2025-08-31 02:35:06,943 - src.core.trainer - INFO - No checkpoint found, starting from scratch
2025-08-31 02:35:06,943 - src.core.trainer - INFO - Trainer initialized for experiment: ppo_pendulum_5M
2025-08-31 02:35:06,943 - src.core.trainer - INFO - Experiment directory: experiments/ppo_pendulum_5M_20250831_023506
2025-08-31 02:35:06,944 - src.utils.config - INFO - Configuration saved to experiments/ppo_pendulum_5M_20250831_023506/configs/config.yaml
2025-08-31 02:35:06,954 - src.core.trainer - INFO - Experiment config saved to experiments/ppo_pendulum_5M_20250831_023506/configs/config.yaml
2025-08-31 02:35:06,955 - __main__ - INFO - Experiment directory: experiments/ppo_pendulum_5M_20250831_023506
2025-08-31 02:35:06,955 - __main__ - INFO - Configuration hash: c3c3d5d7
2025-08-31 02:35:06,955 - __main__ - INFO - Starting training loop...
2025-08-31 02:35:06,955 - src.core.trainer - INFO - Starting training...
2025-08-31 02:35:06,955 - src.core.trainer - INFO - Target steps: 5000000
2025-08-31 02:35:06,955 - src.core.trainer - INFO - Evaluation frequency: 50000
2025-08-31 02:35:06,955 - src.core.trainer - INFO - Checkpoint frequency: 250000
2025-08-31 02:36:55,287 - src.utils.checkpoint - INFO - Checkpoint saved: experiments/ppo_pendulum_5M_20250831_023506/checkpoints/auto_step_251904.pt (step 251904)
2025-08-31 02:36:55,289 - src.core.trainer - INFO - Auto-saved checkpoint at step 251904
2025-08-31 02:38:41,597 - src.utils.checkpoint - INFO - Checkpoint saved: experiments/ppo_pendulum_5M_20250831_023506/checkpoints/auto_step_503808.pt (step 503808)
2025-08-31 02:38:41,598 - src.core.trainer - INFO - Auto-saved checkpoint at step 503808
2025-08-31 02:45:49,984 - src.core.trainer - INFO - Logging setup complete. Log file: experiments/ppo_pendulum_5M_20250831_023506/logs/training.log
2025-08-31 02:45:49,986 - src.utils.registry - INFO - Registered algorithm: ppo -> PPOAlgorithm
2025-08-31 02:45:49,986 - src.utils.registry - INFO - Registered algorithm: random -> RandomAgent
2025-08-31 02:45:49,987 - src.utils.registry - INFO - Registered network: mlp -> MLP
2025-08-31 02:45:49,987 - src.utils.registry - INFO - Registered network: actor_mlp -> ActorMLP
2025-08-31 02:45:49,987 - src.utils.registry - INFO - Registered network: critic_mlp -> CriticMLP
2025-08-31 02:45:49,987 - src.utils.registry - INFO - Registered network: continuous_actor_mlp -> ContinuousActorMLP
2025-08-31 02:45:49,988 - src.utils.registry - INFO - Registered network: dueling_mlp -> DuelingMLP
2025-08-31 02:45:49,989 - src.utils.registry - INFO - Registered environment: gym -> GymWrapper
2025-08-31 02:45:49,990 - src.utils.registry - INFO - Registered buffer: trajectory -> TrajectoryBuffer
2025-08-31 02:45:49,990 - src.core.trainer - INFO - Initializing environment...
2025-08-31 02:45:50,041 - src.environments.gym_wrapper - INFO - Created Gym environment: Pendulum-v1
2025-08-31 02:45:50,041 - src.core.trainer - INFO - Environment: Pendulum-v1
2025-08-31 02:45:50,041 - src.core.trainer - INFO - Observation space: (3,)
2025-08-31 02:45:50,041 - src.core.trainer - INFO - Action space: (1,), discrete: False
2025-08-31 02:45:50,041 - src.core.trainer - INFO - Initializing networks...
2025-08-31 02:45:50,081 - src.core.trainer - INFO - Created actor network: continuous_actor_mlp
2025-08-31 02:45:50,081 - src.core.trainer - INFO - Created critic network: critic_mlp
2025-08-31 02:45:50,081 - src.core.trainer - INFO - Initializing algorithm...
2025-08-31 02:45:50,651 - src.core.trainer - INFO - Created algorithm: ppo
2025-08-31 02:45:50,651 - src.core.trainer - INFO - Initializing buffer...
2025-08-31 02:45:50,651 - src.core.trainer - INFO - Created buffer: trajectory
2025-08-31 02:45:50,654 - src.environments.gym_wrapper - INFO - Seed will be applied on next reset: 42
2025-08-31 02:45:50,654 - src.core.trainer - INFO - Random seeds set to 42
2025-08-31 02:45:50,654 - src.core.trainer - INFO - All components initialized successfully
2025-08-31 02:45:50,654 - src.utils.checkpoint - INFO - Checkpoint manager initialized at experiments/ppo_pendulum_5M_20250831_023506/checkpoints
2025-08-31 02:45:50,655 - src.utils.logger - INFO - TensorBoard logging enabled: experiments/ppo_pendulum_5M_20250831_023506/tensorboard
2025-08-31 02:45:50,655 - src.utils.logger - INFO - Experiment logger initialized: experiments/ppo_pendulum_5M_20250831_023506
2025-08-31 02:45:50,663 - src.utils.checkpoint - INFO - Checkpoint loaded: experiments/ppo_pendulum_5M_20250831_023506/checkpoints/latest.pt (step 503808)
2025-08-31 02:45:50,663 - src.core.trainer - INFO - Resuming from checkpoint...
2025-08-31 02:45:50,691 - src.utils.checkpoint - INFO - Training state restored to step 503808
2025-08-31 02:45:50,691 - src.core.trainer - INFO - Resumed from step 503808
2025-08-31 02:45:50,691 - src.core.trainer - INFO - Trainer initialized for experiment: ppo_pendulum_5M
2025-08-31 02:45:50,691 - src.core.trainer - INFO - Experiment directory: experiments/ppo_pendulum_5M_20250831_023506
2025-08-31 02:45:50,693 - src.utils.config - INFO - Configuration saved to experiments/ppo_pendulum_5M_20250831_023506/configs/config.yaml
2025-08-31 02:45:50,702 - src.core.trainer - INFO - Experiment config saved to experiments/ppo_pendulum_5M_20250831_023506/configs/config.yaml
2025-08-31 02:45:50,702 - __main__ - INFO - Experiment directory: experiments/ppo_pendulum_5M_20250831_023506
2025-08-31 02:45:50,702 - __main__ - INFO - Configuration hash: f4339465
2025-08-31 02:45:50,702 - __main__ - INFO - Starting training loop...
2025-08-31 02:45:50,703 - src.core.trainer - INFO - Starting training...
2025-08-31 02:45:50,703 - src.core.trainer - INFO - Target steps: 5000000
2025-08-31 02:45:50,703 - src.core.trainer - INFO - Evaluation frequency: 50000
2025-08-31 02:45:50,703 - src.core.trainer - INFO - Checkpoint frequency: 250000
2025-08-31 02:45:51,569 - src.utils.checkpoint - INFO - Checkpoint saved: experiments/ppo_pendulum_5M_20250831_023506/checkpoints/auto_step_505856.pt (step 505856)
2025-08-31 02:45:51,572 - src.core.trainer - INFO - Auto-saved checkpoint at step 505856
2025-08-31 02:45:54,060 - src.utils.logger - INFO - Step 512000 | train/policy_loss: 0.2555 | train/value_loss: 27492.8063 | train/entropy_loss: -0.9189 | train/total_loss: 19245.1730 | train/grad_norm: 784.0307 | train/debug/update_mean_avg: 0.2433 | train/debug/update_mean_std: 0.1471 | train/debug/update_mean_min: -0.0687 | train/debug/update_mean_max: 0.4195 | train/debug/update_log_std_avg: -0.1923 | train/debug/update_std_avg: 0.6065 | train/debug/update_std_min: 0.6065 | train/debug/update_std_max: 0.6065 | train/debug/update_action_clipped_pct: 0.0000 | train/debug/update_network_output_shape: 2.0000 | train/debug/returns_mean: -378.4720 | train/debug/returns_std: 162.6705 | train/debug/returns_min: -679.2062 | train/debug/returns_max: -10.3636 | train/debug/advantages_mean: -0.1354 | train/debug/advantages_std: 0.8837 | train/debug/advantages_min: -0.9346 | train/debug/advantages_max: 4.7077 | train/debug/old_values_mean: -321.4699 | train/debug/old_values_std: 24.0734 | train/debug/value_error_mean: 147.6745 | train/time_elapsed: 3.3573 | train/steps_per_second: 152502.6856
2025-08-31 02:45:54,063 - src.utils.logger - INFO - Step 512000 | train/policy_loss: 0.2555 | train/value_loss: 27492.8063 | train/entropy_loss: -0.9189 | train/total_loss: 19245.1730 | train/grad_norm: 784.0307 | train/debug/update_mean_avg: 0.2433 | train/debug/update_mean_std: 0.1471 | train/debug/update_mean_min: -0.0687 | train/debug/update_mean_max: 0.4195 | train/debug/update_log_std_avg: -0.1923 | train/debug/update_std_avg: 0.6065 | train/debug/update_std_min: 0.6065 | train/debug/update_std_max: 0.6065 | train/debug/update_action_clipped_pct: 0.0000 | train/debug/update_network_output_shape: 2.0000 | train/debug/returns_mean: -378.4720 | train/debug/returns_std: 162.6705 | train/debug/returns_min: -679.2062 | train/debug/returns_max: -10.3636 | train/debug/advantages_mean: -0.1354 | train/debug/advantages_std: 0.8837 | train/debug/advantages_min: -0.9346 | train/debug/advantages_max: 4.7077 | train/debug/old_values_mean: -321.4699 | train/debug/old_values_std: 24.0734 | train/debug/value_error_mean: 147.6745 | train/time_elapsed: 3.3599 | train/steps_per_second: 152383.6712
2025-08-31 02:47:29,448 - src.utils.checkpoint - INFO - Checkpoint saved: experiments/ppo_pendulum_5M_20250831_023506/checkpoints/auto_step_757760.pt (step 757760)
2025-08-31 02:47:29,449 - src.core.trainer - INFO - Auto-saved checkpoint at step 757760
2025-08-31 02:47:33,569 - src.utils.logger - INFO - Step 768000 | train/policy_loss: 0.2516 | train/value_loss: 22604.4712 | train/entropy_loss: -0.9189 | train/total_loss: 15823.3350 | train/grad_norm: 677.1746 | train/debug/update_mean_avg: 0.2763 | train/debug/update_mean_std: 0.1272 | train/debug/update_mean_min: -0.0652 | train/debug/update_mean_max: 0.4099 | train/debug/update_log_std_avg: -0.2523 | train/debug/update_std_avg: 0.6065 | train/debug/update_std_min: 0.6065 | train/debug/update_std_max: 0.6065 | train/debug/update_action_clipped_pct: 0.0000 | train/debug/update_network_output_shape: 2.0000 | train/debug/returns_mean: -346.6939 | train/debug/returns_std: 170.2998 | train/debug/returns_min: -648.6813 | train/debug/returns_max: -9.1114 | train/debug/advantages_mean: 0.1790 | train/debug/advantages_std: 1.5022 | train/debug/advantages_min: -0.9861 | train/debug/advantages_max: 5.8893 | train/debug/old_values_mean: -319.7728 | train/debug/old_values_std: 87.6010 | train/debug/value_error_mean: 140.4258 | train/time_elapsed: 102.8663 | train/steps_per_second: 7466.0004
2025-08-31 02:47:33,571 - src.utils.logger - INFO - Step 768000 | train/policy_loss: 0.2516 | train/value_loss: 22604.4712 | train/entropy_loss: -0.9189 | train/total_loss: 15823.3350 | train/grad_norm: 677.1746 | train/debug/update_mean_avg: 0.2763 | train/debug/update_mean_std: 0.1272 | train/debug/update_mean_min: -0.0652 | train/debug/update_mean_max: 0.4099 | train/debug/update_log_std_avg: -0.2523 | train/debug/update_std_avg: 0.6065 | train/debug/update_std_min: 0.6065 | train/debug/update_std_max: 0.6065 | train/debug/update_action_clipped_pct: 0.0000 | train/debug/update_network_output_shape: 2.0000 | train/debug/returns_mean: -346.6939 | train/debug/returns_std: 170.2998 | train/debug/returns_min: -648.6813 | train/debug/returns_max: -9.1114 | train/debug/advantages_mean: 0.1790 | train/debug/advantages_std: 1.5022 | train/debug/advantages_min: -0.9861 | train/debug/advantages_max: 5.8893 | train/debug/old_values_mean: -319.7728 | train/debug/old_values_std: 87.6010 | train/debug/value_error_mean: 140.4258 | train/time_elapsed: 102.8684 | train/steps_per_second: 7465.8480
2025-08-31 05:47:42,919 - src.core.trainer - INFO - Logging setup complete. Log file: experiments/ppo_pendulum_5M_20250831_023506/logs/training.log
2025-08-31 05:47:42,920 - src.utils.registry - INFO - Registered algorithm: ppo -> PPOAlgorithm
2025-08-31 05:47:42,921 - src.utils.registry - INFO - Registered algorithm: random -> RandomAgent
2025-08-31 05:47:42,921 - src.utils.registry - INFO - Registered network: mlp -> MLP
2025-08-31 05:47:42,921 - src.utils.registry - INFO - Registered network: actor_mlp -> ActorMLP
2025-08-31 05:47:42,921 - src.utils.registry - INFO - Registered network: critic_mlp -> CriticMLP
2025-08-31 05:47:42,922 - src.utils.registry - INFO - Registered network: continuous_actor_mlp -> ContinuousActorMLP
2025-08-31 05:47:42,922 - src.utils.registry - INFO - Registered network: dueling_mlp -> DuelingMLP
2025-08-31 05:47:42,923 - src.utils.registry - INFO - Registered environment: gym -> GymWrapper
2025-08-31 05:47:42,924 - src.utils.registry - INFO - Registered buffer: trajectory -> TrajectoryBuffer
2025-08-31 05:47:42,924 - src.core.trainer - INFO - Initializing environment...
2025-08-31 05:47:42,974 - src.environments.gym_wrapper - INFO - Created Gym environment: Pendulum-v1
2025-08-31 05:47:42,974 - src.core.trainer - INFO - Environment: Pendulum-v1
2025-08-31 05:47:42,974 - src.core.trainer - INFO - Observation space: (3,)
2025-08-31 05:47:42,974 - src.core.trainer - INFO - Action space: (1,), discrete: False
2025-08-31 05:47:42,974 - src.core.trainer - INFO - Initializing networks...
2025-08-31 05:47:43,017 - src.core.trainer - INFO - Created actor network: continuous_actor_mlp
2025-08-31 05:47:43,017 - src.core.trainer - INFO - Created critic network: critic_mlp
2025-08-31 05:47:43,017 - src.core.trainer - INFO - Initializing algorithm...
2025-08-31 05:47:43,577 - src.core.trainer - INFO - Created algorithm: ppo
2025-08-31 05:47:43,577 - src.core.trainer - INFO - Initializing buffer...
2025-08-31 05:47:43,577 - src.core.trainer - INFO - Created buffer: trajectory
2025-08-31 05:47:43,580 - src.environments.gym_wrapper - INFO - Seed will be applied on next reset: 42
2025-08-31 05:47:43,580 - src.core.trainer - INFO - Random seeds set to 42
2025-08-31 05:47:43,580 - src.core.trainer - INFO - All components initialized successfully
2025-08-31 05:47:43,580 - src.utils.checkpoint - INFO - Checkpoint manager initialized at experiments/ppo_pendulum_5M_20250831_023506/checkpoints
2025-08-31 05:47:43,581 - src.utils.logger - INFO - TensorBoard logging enabled: experiments/ppo_pendulum_5M_20250831_023506/tensorboard
2025-08-31 05:47:43,581 - src.utils.logger - INFO - Experiment logger initialized: experiments/ppo_pendulum_5M_20250831_023506
2025-08-31 05:47:43,589 - src.utils.checkpoint - INFO - Checkpoint loaded: experiments/ppo_pendulum_5M_20250831_023506/checkpoints/latest.pt (step 757760)
2025-08-31 05:47:43,589 - src.core.trainer - INFO - Resuming from checkpoint...
2025-08-31 05:47:43,613 - src.utils.checkpoint - INFO - Training state restored to step 757760
2025-08-31 05:47:43,613 - src.core.trainer - INFO - Resumed from step 757760
2025-08-31 05:47:43,613 - src.core.trainer - INFO - Trainer initialized for experiment: ppo_pendulum_5M
2025-08-31 05:47:43,613 - src.core.trainer - INFO - Experiment directory: experiments/ppo_pendulum_5M_20250831_023506
2025-08-31 05:47:43,615 - src.utils.config - INFO - Configuration saved to experiments/ppo_pendulum_5M_20250831_023506/configs/config.yaml
2025-08-31 05:47:43,624 - src.core.trainer - INFO - Experiment config saved to experiments/ppo_pendulum_5M_20250831_023506/configs/config.yaml
2025-08-31 05:47:43,624 - __main__ - INFO - Experiment directory: experiments/ppo_pendulum_5M_20250831_023506
2025-08-31 05:47:43,625 - __main__ - INFO - Configuration hash: f4339465
2025-08-31 05:47:43,625 - __main__ - INFO - Starting training loop...
2025-08-31 05:47:43,625 - src.core.trainer - INFO - Starting training...
2025-08-31 05:47:43,625 - src.core.trainer - INFO - Target steps: 5000000
2025-08-31 05:47:43,625 - src.core.trainer - INFO - Evaluation frequency: 50000
2025-08-31 05:47:43,625 - src.core.trainer - INFO - Checkpoint frequency: 250000
2025-08-31 05:47:44,488 - src.utils.checkpoint - INFO - Checkpoint saved: experiments/ppo_pendulum_5M_20250831_023506/checkpoints/auto_step_759808.pt (step 759808)
2025-08-31 05:47:44,489 - src.core.trainer - INFO - Auto-saved checkpoint at step 759808
2025-08-31 05:47:47,585 - src.utils.logger - INFO - Step 768000 | train/policy_loss: 0.2642 | train/value_loss: 17504.0377 | train/entropy_loss: -0.9189 | train/total_loss: 12253.0444 | train/grad_norm: 1181.2904 | train/debug/update_mean_avg: 0.2136 | train/debug/update_mean_std: 0.1602 | train/debug/update_mean_min: -0.0691 | train/debug/update_mean_max: 0.4156 | train/debug/update_log_std_avg: -0.2460 | train/debug/update_std_avg: 0.6065 | train/debug/update_std_min: 0.6065 | train/debug/update_std_max: 0.6065 | train/debug/update_action_clipped_pct: 0.0000 | train/debug/update_network_output_shape: 2.0000 | train/debug/returns_mean: -338.5286 | train/debug/returns_std: 134.7271 | train/debug/returns_min: -618.0827 | train/debug/returns_max: -4.3431 | train/debug/advantages_mean: -0.0951 | train/debug/advantages_std: 0.9606 | train/debug/advantages_min: -1.1323 | train/debug/advantages_max: 4.4091 | train/debug/old_values_mean: -316.9563 | train/debug/old_values_std: 66.2561 | train/debug/value_error_mean: 104.3055 | train/time_elapsed: 3.9603 | train/steps_per_second: 193924.2606
2025-08-31 05:47:47,587 - src.utils.logger - INFO - Step 768000 | train/policy_loss: 0.2642 | train/value_loss: 17504.0377 | train/entropy_loss: -0.9189 | train/total_loss: 12253.0444 | train/grad_norm: 1181.2904 | train/debug/update_mean_avg: 0.2136 | train/debug/update_mean_std: 0.1602 | train/debug/update_mean_min: -0.0691 | train/debug/update_mean_max: 0.4156 | train/debug/update_log_std_avg: -0.2460 | train/debug/update_std_avg: 0.6065 | train/debug/update_std_min: 0.6065 | train/debug/update_std_max: 0.6065 | train/debug/update_action_clipped_pct: 0.0000 | train/debug/update_network_output_shape: 2.0000 | train/debug/returns_mean: -338.5286 | train/debug/returns_std: 134.7271 | train/debug/returns_min: -618.0827 | train/debug/returns_max: -4.3431 | train/debug/advantages_mean: -0.0951 | train/debug/advantages_std: 0.9606 | train/debug/advantages_min: -1.1323 | train/debug/advantages_max: 4.4091 | train/debug/old_values_mean: -316.9563 | train/debug/old_values_std: 66.2561 | train/debug/value_error_mean: 104.3055 | train/time_elapsed: 3.9625 | train/steps_per_second: 193816.3886
2025-08-31 05:49:24,750 - src.utils.checkpoint - INFO - Checkpoint saved: experiments/ppo_pendulum_5M_20250831_023506/checkpoints/auto_step_1011712.pt (step 1011712)
2025-08-31 05:49:24,752 - src.core.trainer - INFO - Auto-saved checkpoint at step 1011712
2025-08-31 05:49:29,887 - src.utils.logger - INFO - Step 1024000 | train/policy_loss: 0.2484 | train/value_loss: 17407.0246 | train/entropy_loss: -0.9189 | train/total_loss: 12185.1195 | train/grad_norm: 854.9988 | train/debug/update_mean_avg: 0.2353 | train/debug/update_mean_std: 0.1613 | train/debug/update_mean_min: -0.0744 | train/debug/update_mean_max: 0.4173 | train/debug/update_log_std_avg: -0.2637 | train/debug/update_std_avg: 0.6065 | train/debug/update_std_min: 0.6065 | train/debug/update_std_max: 0.6065 | train/debug/update_action_clipped_pct: 0.0000 | train/debug/update_network_output_shape: 2.0000 | train/debug/returns_mean: -313.4535 | train/debug/returns_std: 143.3874 | train/debug/returns_min: -632.0800 | train/debug/returns_max: -12.4519 | train/debug/advantages_mean: -0.0534 | train/debug/advantages_std: 0.9027 | train/debug/advantages_min: -0.9816 | train/debug/advantages_max: 4.1189 | train/debug/old_values_mean: -301.0820 | train/debug/old_values_std: 59.6478 | train/debug/value_error_mean: 89.3379 | train/time_elapsed: 106.2618 | train/steps_per_second: 9636.5812
2025-08-31 05:49:29,889 - src.utils.logger - INFO - Step 1024000 | train/policy_loss: 0.2484 | train/value_loss: 17407.0246 | train/entropy_loss: -0.9189 | train/total_loss: 12185.1195 | train/grad_norm: 854.9988 | train/debug/update_mean_avg: 0.2353 | train/debug/update_mean_std: 0.1613 | train/debug/update_mean_min: -0.0744 | train/debug/update_mean_max: 0.4173 | train/debug/update_log_std_avg: -0.2637 | train/debug/update_std_avg: 0.6065 | train/debug/update_std_min: 0.6065 | train/debug/update_std_max: 0.6065 | train/debug/update_action_clipped_pct: 0.0000 | train/debug/update_network_output_shape: 2.0000 | train/debug/returns_mean: -313.4535 | train/debug/returns_std: 143.3874 | train/debug/returns_min: -632.0800 | train/debug/returns_max: -12.4519 | train/debug/advantages_mean: -0.0534 | train/debug/advantages_std: 0.9027 | train/debug/advantages_min: -0.9816 | train/debug/advantages_max: 4.1189 | train/debug/old_values_mean: -301.0820 | train/debug/old_values_std: 59.6478 | train/debug/value_error_mean: 89.3379 | train/time_elapsed: 106.2643 | train/steps_per_second: 9636.3459
2025-08-31 05:51:09,435 - src.utils.checkpoint - INFO - Checkpoint saved: experiments/ppo_pendulum_5M_20250831_023506/checkpoints/auto_step_1263616.pt (step 1263616)
2025-08-31 05:51:09,437 - src.core.trainer - INFO - Auto-saved checkpoint at step 1263616
2025-08-31 05:51:16,219 - src.utils.logger - INFO - Step 1280000 | train/policy_loss: 0.2500 | train/value_loss: 22283.5654 | train/entropy_loss: -0.9189 | train/total_loss: 15598.6994 | train/grad_norm: 860.0731 | train/debug/update_mean_avg: 0.1915 | train/debug/update_mean_std: 0.1348 | train/debug/update_mean_min: -0.0693 | train/debug/update_mean_max: 0.3929 | train/debug/update_log_std_avg: -0.2037 | train/debug/update_std_avg: 0.6065 | train/debug/update_std_min: 0.6065 | train/debug/update_std_max: 0.6065 | train/debug/update_action_clipped_pct: 0.0000 | train/debug/update_network_output_shape: 2.0000 | train/debug/returns_mean: -300.8932 | train/debug/returns_std: 185.2245 | train/debug/returns_min: -717.0746 | train/debug/returns_max: -3.3081 | train/debug/advantages_mean: 0.1182 | train/debug/advantages_std: 1.0933 | train/debug/advantages_min: -0.8558 | train/debug/advantages_max: 5.5922 | train/debug/old_values_mean: -341.5175 | train/debug/old_values_std: 116.2728 | train/debug/value_error_mean: 116.7348 | train/time_elapsed: 212.5944 | train/steps_per_second: 6020.8536
2025-08-31 05:51:16,222 - src.utils.logger - INFO - Step 1280000 | train/policy_loss: 0.2500 | train/value_loss: 22283.5654 | train/entropy_loss: -0.9189 | train/total_loss: 15598.6994 | train/grad_norm: 860.0731 | train/debug/update_mean_avg: 0.1915 | train/debug/update_mean_std: 0.1348 | train/debug/update_mean_min: -0.0693 | train/debug/update_mean_max: 0.3929 | train/debug/update_log_std_avg: -0.2037 | train/debug/update_std_avg: 0.6065 | train/debug/update_std_min: 0.6065 | train/debug/update_std_max: 0.6065 | train/debug/update_action_clipped_pct: 0.0000 | train/debug/update_network_output_shape: 2.0000 | train/debug/returns_mean: -300.8932 | train/debug/returns_std: 185.2245 | train/debug/returns_min: -717.0746 | train/debug/returns_max: -3.3081 | train/debug/advantages_mean: 0.1182 | train/debug/advantages_std: 1.0933 | train/debug/advantages_min: -0.8558 | train/debug/advantages_max: 5.5922 | train/debug/old_values_mean: -341.5175 | train/debug/old_values_std: 116.2728 | train/debug/value_error_mean: 116.7348 | train/time_elapsed: 212.5976 | train/steps_per_second: 6020.7654
2025-08-31 05:52:52,933 - src.utils.checkpoint - INFO - Checkpoint saved: experiments/ppo_pendulum_5M_20250831_023506/checkpoints/auto_step_1515520.pt (step 1515520)
2025-08-31 05:52:52,936 - src.core.trainer - INFO - Auto-saved checkpoint at step 1515520
2025-08-31 05:53:01,277 - src.utils.logger - INFO - Step 1536000 | train/policy_loss: 0.2541 | train/value_loss: 15638.7563 | train/entropy_loss: -0.9189 | train/total_loss: 10947.3374 | train/grad_norm: 1544.1974 | train/debug/update_mean_avg: 0.2479 | train/debug/update_mean_std: 0.1570 | train/debug/update_mean_min: -0.0754 | train/debug/update_mean_max: 0.4185 | train/debug/update_log_std_avg: -0.2658 | train/debug/update_std_avg: 0.6065 | train/debug/update_std_min: 0.6065 | train/debug/update_std_max: 0.6065 | train/debug/update_action_clipped_pct: 0.0000 | train/debug/update_network_output_shape: 2.0000 | train/debug/returns_mean: -299.7935 | train/debug/returns_std: 141.9472 | train/debug/returns_min: -578.4470 | train/debug/returns_max: -3.6175 | train/debug/advantages_mean: -0.0232 | train/debug/advantages_std: 1.0196 | train/debug/advantages_min: -1.0523 | train/debug/advantages_max: 3.7790 | train/debug/old_values_mean: -297.7646 | train/debug/old_values_std: 56.2639 | train/debug/value_error_mean: 104.5309 | train/time_elapsed: 317.6521 | train/steps_per_second: 4835.4788
2025-08-31 05:53:01,280 - src.utils.logger - INFO - Step 1536000 | train/policy_loss: 0.2541 | train/value_loss: 15638.7563 | train/entropy_loss: -0.9189 | train/total_loss: 10947.3374 | train/grad_norm: 1544.1974 | train/debug/update_mean_avg: 0.2479 | train/debug/update_mean_std: 0.1570 | train/debug/update_mean_min: -0.0754 | train/debug/update_mean_max: 0.4185 | train/debug/update_log_std_avg: -0.2658 | train/debug/update_std_avg: 0.6065 | train/debug/update_std_min: 0.6065 | train/debug/update_std_max: 0.6065 | train/debug/update_action_clipped_pct: 0.0000 | train/debug/update_network_output_shape: 2.0000 | train/debug/returns_mean: -299.7935 | train/debug/returns_std: 141.9472 | train/debug/returns_min: -578.4470 | train/debug/returns_max: -3.6175 | train/debug/advantages_mean: -0.0232 | train/debug/advantages_std: 1.0196 | train/debug/advantages_min: -1.0523 | train/debug/advantages_max: 3.7790 | train/debug/old_values_mean: -297.7646 | train/debug/old_values_std: 56.2639 | train/debug/value_error_mean: 104.5309 | train/time_elapsed: 317.6557 | train/steps_per_second: 4835.4245
2025-08-31 05:54:35,862 - src.utils.checkpoint - INFO - Checkpoint saved: experiments/ppo_pendulum_5M_20250831_023506/checkpoints/auto_step_1767424.pt (step 1767424)
2025-08-31 05:54:35,863 - src.core.trainer - INFO - Auto-saved checkpoint at step 1767424
2025-08-31 05:55:33,973 - src.core.trainer - INFO - Logging setup complete. Log file: experiments/ppo_pendulum_5M_20250831_023506/logs/training.log
2025-08-31 05:55:33,974 - src.utils.registry - INFO - Registered algorithm: ppo -> PPOAlgorithm
2025-08-31 05:55:33,975 - src.utils.registry - INFO - Registered algorithm: random -> RandomAgent
2025-08-31 05:55:33,976 - src.utils.registry - INFO - Registered network: mlp -> MLP
2025-08-31 05:55:33,976 - src.utils.registry - INFO - Registered network: actor_mlp -> ActorMLP
2025-08-31 05:55:33,976 - src.utils.registry - INFO - Registered network: critic_mlp -> CriticMLP
2025-08-31 05:55:33,976 - src.utils.registry - INFO - Registered network: continuous_actor_mlp -> ContinuousActorMLP
2025-08-31 05:55:33,976 - src.utils.registry - INFO - Registered network: dueling_mlp -> DuelingMLP
2025-08-31 05:55:33,978 - src.utils.registry - INFO - Registered environment: gym -> GymWrapper
2025-08-31 05:55:33,979 - src.utils.registry - INFO - Registered buffer: trajectory -> TrajectoryBuffer
2025-08-31 05:55:33,979 - src.core.trainer - INFO - Initializing environment...
2025-08-31 05:55:34,032 - src.environments.gym_wrapper - INFO - Created Gym environment: Pendulum-v1
2025-08-31 05:55:34,032 - src.core.trainer - INFO - Environment: Pendulum-v1
2025-08-31 05:55:34,032 - src.core.trainer - INFO - Observation space: (3,)
2025-08-31 05:55:34,032 - src.core.trainer - INFO - Action space: (1,), discrete: False
2025-08-31 05:55:34,032 - src.core.trainer - INFO - Initializing networks...
2025-08-31 05:55:34,069 - src.core.trainer - INFO - Created actor network: continuous_actor_mlp
2025-08-31 05:55:34,069 - src.core.trainer - INFO - Created critic network: critic_mlp
2025-08-31 05:55:34,069 - src.core.trainer - INFO - Initializing algorithm...
2025-08-31 05:55:34,619 - src.core.trainer - INFO - Created algorithm: ppo
2025-08-31 05:55:34,619 - src.core.trainer - INFO - Initializing buffer...
2025-08-31 05:55:34,619 - src.core.trainer - INFO - Created buffer: trajectory
2025-08-31 05:55:34,622 - src.environments.gym_wrapper - INFO - Seed will be applied on next reset: 42
2025-08-31 05:55:34,622 - src.core.trainer - INFO - Random seeds set to 42
2025-08-31 05:55:34,622 - src.core.trainer - INFO - All components initialized successfully
2025-08-31 05:55:34,622 - src.utils.checkpoint - INFO - Checkpoint manager initialized at experiments/ppo_pendulum_5M_20250831_023506/checkpoints
2025-08-31 05:55:34,623 - src.utils.logger - INFO - TensorBoard logging enabled: experiments/ppo_pendulum_5M_20250831_023506/tensorboard
2025-08-31 05:55:34,623 - src.utils.logger - INFO - Experiment logger initialized: experiments/ppo_pendulum_5M_20250831_023506
2025-08-31 05:55:34,630 - src.utils.checkpoint - INFO - Checkpoint loaded: experiments/ppo_pendulum_5M_20250831_023506/checkpoints/latest.pt (step 1767424)
2025-08-31 05:55:34,630 - src.core.trainer - INFO - Resuming from checkpoint...
2025-08-31 05:55:34,655 - src.utils.checkpoint - INFO - Training state restored to step 1767424
2025-08-31 05:55:34,655 - src.core.trainer - INFO - Resumed from step 1767424
2025-08-31 05:55:34,655 - src.core.trainer - INFO - Trainer initialized for experiment: ppo_pendulum_5M
2025-08-31 05:55:34,655 - src.core.trainer - INFO - Experiment directory: experiments/ppo_pendulum_5M_20250831_023506
2025-08-31 05:55:34,657 - src.utils.config - INFO - Configuration saved to experiments/ppo_pendulum_5M_20250831_023506/configs/config.yaml
2025-08-31 05:55:34,666 - src.core.trainer - INFO - Experiment config saved to experiments/ppo_pendulum_5M_20250831_023506/configs/config.yaml
2025-08-31 05:55:34,666 - __main__ - INFO - Experiment directory: experiments/ppo_pendulum_5M_20250831_023506
2025-08-31 05:55:34,666 - __main__ - INFO - Configuration hash: f4339465
2025-08-31 05:55:34,666 - __main__ - INFO - Starting training loop...
2025-08-31 05:55:34,666 - src.core.trainer - INFO - Starting training...
2025-08-31 05:55:34,666 - src.core.trainer - INFO - Target steps: 5000000
2025-08-31 05:55:34,666 - src.core.trainer - INFO - Evaluation frequency: 50000
2025-08-31 05:55:34,667 - src.core.trainer - INFO - Checkpoint frequency: 250000
2025-08-31 05:55:35,522 - src.utils.checkpoint - INFO - Checkpoint saved: experiments/ppo_pendulum_5M_20250831_023506/checkpoints/auto_step_1769472.pt (step 1769472)
2025-08-31 05:55:35,524 - src.core.trainer - INFO - Auto-saved checkpoint at step 1769472
2025-08-31 05:55:44,400 - src.utils.logger - INFO - Step 1792000 | train/policy_loss: 0.2534 | train/value_loss: 17464.0874 | train/entropy_loss: -0.9189 | train/total_loss: 12225.0685 | train/grad_norm: 581.3853 | train/debug/update_mean_avg: 0.1705 | train/debug/update_mean_std: 0.1735 | train/debug/update_mean_min: -0.0765 | train/debug/update_mean_max: 0.4192 | train/debug/update_log_std_avg: -0.2053 | train/debug/update_std_avg: 0.6065 | train/debug/update_std_min: 0.6065 | train/debug/update_std_max: 0.6065 | train/debug/update_action_clipped_pct: 0.0000 | train/debug/update_network_output_shape: 2.0000 | train/debug/returns_mean: -312.8434 | train/debug/returns_std: 158.8926 | train/debug/returns_min: -620.6513 | train/debug/returns_max: -17.2373 | train/debug/advantages_mean: 0.0106 | train/debug/advantages_std: 0.8196 | train/debug/advantages_min: -0.9076 | train/debug/advantages_max: 3.7026 | train/debug/old_values_mean: -354.0168 | train/debug/old_values_std: 65.0049 | train/debug/value_error_mean: 107.5980 | train/time_elapsed: 9.7330 | train/steps_per_second: 184116.4844
2025-08-31 05:55:44,403 - src.utils.logger - INFO - Step 1792000 | train/policy_loss: 0.2534 | train/value_loss: 17464.0874 | train/entropy_loss: -0.9189 | train/total_loss: 12225.0685 | train/grad_norm: 581.3853 | train/debug/update_mean_avg: 0.1705 | train/debug/update_mean_std: 0.1735 | train/debug/update_mean_min: -0.0765 | train/debug/update_mean_max: 0.4192 | train/debug/update_log_std_avg: -0.2053 | train/debug/update_std_avg: 0.6065 | train/debug/update_std_min: 0.6065 | train/debug/update_std_max: 0.6065 | train/debug/update_action_clipped_pct: 0.0000 | train/debug/update_network_output_shape: 2.0000 | train/debug/returns_mean: -312.8434 | train/debug/returns_std: 158.8926 | train/debug/returns_min: -620.6513 | train/debug/returns_max: -17.2373 | train/debug/advantages_mean: 0.0106 | train/debug/advantages_std: 0.8196 | train/debug/advantages_min: -0.9076 | train/debug/advantages_max: 3.7026 | train/debug/old_values_mean: -354.0168 | train/debug/old_values_std: 65.0049 | train/debug/value_error_mean: 107.5980 | train/time_elapsed: 9.7367 | train/steps_per_second: 184045.6849
2025-08-31 05:57:17,522 - src.utils.checkpoint - INFO - Checkpoint saved: experiments/ppo_pendulum_5M_20250831_023506/checkpoints/auto_step_2021376.pt (step 2021376)
2025-08-31 05:57:17,525 - src.core.trainer - INFO - Auto-saved checkpoint at step 2021376
2025-08-31 05:57:28,172 - src.utils.logger - INFO - Step 2048000 | train/policy_loss: 0.2559 | train/value_loss: 19773.8182 | train/entropy_loss: -0.9189 | train/total_loss: 13841.8825 | train/grad_norm: 1113.7162 | train/debug/update_mean_avg: 0.2314 | train/debug/update_mean_std: 0.1512 | train/debug/update_mean_min: -0.0730 | train/debug/update_mean_max: 0.4178 | train/debug/update_log_std_avg: -0.2221 | train/debug/update_std_avg: 0.6065 | train/debug/update_std_min: 0.6065 | train/debug/update_std_max: 0.6065 | train/debug/update_action_clipped_pct: 0.0000 | train/debug/update_network_output_shape: 2.0000 | train/debug/returns_mean: -310.1402 | train/debug/returns_std: 205.7581 | train/debug/returns_min: -775.3740 | train/debug/returns_max: -0.8472 | train/debug/advantages_mean: 0.2606 | train/debug/advantages_std: 1.2274 | train/debug/advantages_min: -0.8606 | train/debug/advantages_max: 3.9543 | train/debug/old_values_mean: -346.0749 | train/debug/old_values_std: 117.7818 | train/debug/value_error_mean: 138.9656 | train/time_elapsed: 113.5050 | train/steps_per_second: 18043.2515
2025-08-31 05:57:28,174 - src.utils.logger - INFO - Step 2048000 | train/policy_loss: 0.2559 | train/value_loss: 19773.8182 | train/entropy_loss: -0.9189 | train/total_loss: 13841.8825 | train/grad_norm: 1113.7162 | train/debug/update_mean_avg: 0.2314 | train/debug/update_mean_std: 0.1512 | train/debug/update_mean_min: -0.0730 | train/debug/update_mean_max: 0.4178 | train/debug/update_log_std_avg: -0.2221 | train/debug/update_std_avg: 0.6065 | train/debug/update_std_min: 0.6065 | train/debug/update_std_max: 0.6065 | train/debug/update_action_clipped_pct: 0.0000 | train/debug/update_network_output_shape: 2.0000 | train/debug/returns_mean: -310.1402 | train/debug/returns_std: 205.7581 | train/debug/returns_min: -775.3740 | train/debug/returns_max: -0.8472 | train/debug/advantages_mean: 0.2606 | train/debug/advantages_std: 1.2274 | train/debug/advantages_min: -0.8606 | train/debug/advantages_max: 3.9543 | train/debug/old_values_mean: -346.0749 | train/debug/old_values_std: 117.7818 | train/debug/value_error_mean: 138.9656 | train/time_elapsed: 113.5074 | train/steps_per_second: 18042.8732
2025-08-31 05:58:59,475 - src.utils.checkpoint - INFO - Checkpoint saved: experiments/ppo_pendulum_5M_20250831_023506/checkpoints/auto_step_2273280.pt (step 2273280)
2025-08-31 05:58:59,476 - src.core.trainer - INFO - Auto-saved checkpoint at step 2273280
2025-08-31 05:59:12,146 - src.utils.logger - INFO - Step 2304000 | train/policy_loss: 0.2580 | train/value_loss: 18746.9369 | train/entropy_loss: -0.9189 | train/total_loss: 13123.0676 | train/grad_norm: 477.4982 | train/debug/update_mean_avg: 0.2175 | train/debug/update_mean_std: 0.1595 | train/debug/update_mean_min: -0.0733 | train/debug/update_mean_max: 0.4194 | train/debug/update_log_std_avg: -0.2160 | train/debug/update_std_avg: 0.6065 | train/debug/update_std_min: 0.6065 | train/debug/update_std_max: 0.6065 | train/debug/update_action_clipped_pct: 0.0000 | train/debug/update_network_output_shape: 2.0000 | train/debug/returns_mean: -323.7809 | train/debug/returns_std: 159.1819 | train/debug/returns_min: -769.0627 | train/debug/returns_max: -13.7207 | train/debug/advantages_mean: -0.0552 | train/debug/advantages_std: 0.8441 | train/debug/advantages_min: -1.0677 | train/debug/advantages_max: 3.4019 | train/debug/old_values_mean: -333.2562 | train/debug/old_values_std: 108.8172 | train/debug/value_error_mean: 87.5226 | train/time_elapsed: 217.4794 | train/steps_per_second: 10594.1080
2025-08-31 05:59:12,148 - src.utils.logger - INFO - Step 2304000 | train/policy_loss: 0.2580 | train/value_loss: 18746.9369 | train/entropy_loss: -0.9189 | train/total_loss: 13123.0676 | train/grad_norm: 477.4982 | train/debug/update_mean_avg: 0.2175 | train/debug/update_mean_std: 0.1595 | train/debug/update_mean_min: -0.0733 | train/debug/update_mean_max: 0.4194 | train/debug/update_log_std_avg: -0.2160 | train/debug/update_std_avg: 0.6065 | train/debug/update_std_min: 0.6065 | train/debug/update_std_max: 0.6065 | train/debug/update_action_clipped_pct: 0.0000 | train/debug/update_network_output_shape: 2.0000 | train/debug/returns_mean: -323.7809 | train/debug/returns_std: 159.1819 | train/debug/returns_min: -769.0627 | train/debug/returns_max: -13.7207 | train/debug/advantages_mean: -0.0552 | train/debug/advantages_std: 0.8441 | train/debug/advantages_min: -1.0677 | train/debug/advantages_max: 3.4019 | train/debug/old_values_mean: -333.2562 | train/debug/old_values_std: 108.8172 | train/debug/value_error_mean: 87.5226 | train/time_elapsed: 217.4818 | train/steps_per_second: 10593.9891
2025-08-31 06:02:23,598 - src.core.trainer - INFO - Logging setup complete. Log file: experiments/ppo_pendulum_5M_20250831_023506/logs/training.log
2025-08-31 06:02:23,601 - src.utils.registry - INFO - Registered algorithm: ppo -> PPOAlgorithm
2025-08-31 06:02:23,601 - src.utils.registry - INFO - Registered algorithm: random -> RandomAgent
2025-08-31 06:02:23,602 - src.utils.registry - INFO - Registered network: mlp -> MLP
2025-08-31 06:02:23,602 - src.utils.registry - INFO - Registered network: actor_mlp -> ActorMLP
2025-08-31 06:02:23,603 - src.utils.registry - INFO - Registered network: critic_mlp -> CriticMLP
2025-08-31 06:02:23,603 - src.utils.registry - INFO - Registered network: continuous_actor_mlp -> ContinuousActorMLP
2025-08-31 06:02:23,603 - src.utils.registry - INFO - Registered network: dueling_mlp -> DuelingMLP
2025-08-31 06:02:23,604 - src.utils.registry - INFO - Registered environment: gym -> GymWrapper
2025-08-31 06:02:23,605 - src.utils.registry - INFO - Registered buffer: trajectory -> TrajectoryBuffer
2025-08-31 06:02:23,605 - src.core.trainer - INFO - Initializing environment...
2025-08-31 06:02:23,655 - src.environments.gym_wrapper - INFO - Created Gym environment: Pendulum-v1
2025-08-31 06:02:23,655 - src.core.trainer - INFO - Environment: Pendulum-v1
2025-08-31 06:02:23,655 - src.core.trainer - INFO - Observation space: (3,)
2025-08-31 06:02:23,655 - src.core.trainer - INFO - Action space: (1,), discrete: False
2025-08-31 06:02:23,655 - src.core.trainer - INFO - Initializing networks...
2025-08-31 06:02:23,693 - src.core.trainer - INFO - Created actor network: continuous_actor_mlp
2025-08-31 06:02:23,694 - src.core.trainer - INFO - Created critic network: critic_mlp
2025-08-31 06:02:23,694 - src.core.trainer - INFO - Initializing algorithm...
2025-08-31 06:02:24,269 - src.core.trainer - INFO - Created algorithm: ppo
2025-08-31 06:02:24,269 - src.core.trainer - INFO - Initializing buffer...
2025-08-31 06:02:24,269 - src.core.trainer - INFO - Created buffer: trajectory
2025-08-31 06:02:24,272 - src.environments.gym_wrapper - INFO - Seed will be applied on next reset: 42
2025-08-31 06:02:24,272 - src.core.trainer - INFO - Random seeds set to 42
2025-08-31 06:02:24,272 - src.core.trainer - INFO - All components initialized successfully
2025-08-31 06:02:24,272 - src.utils.checkpoint - INFO - Checkpoint manager initialized at experiments/ppo_pendulum_5M_20250831_023506/checkpoints
2025-08-31 06:02:24,273 - src.utils.logger - INFO - TensorBoard logging enabled: experiments/ppo_pendulum_5M_20250831_023506/tensorboard
2025-08-31 06:02:24,273 - src.utils.logger - INFO - Experiment logger initialized: experiments/ppo_pendulum_5M_20250831_023506
2025-08-31 06:02:24,280 - src.utils.checkpoint - INFO - Checkpoint loaded: experiments/ppo_pendulum_5M_20250831_023506/checkpoints/latest.pt (step 2273280)
2025-08-31 06:02:24,280 - src.core.trainer - INFO - Resuming from checkpoint...
2025-08-31 06:02:24,305 - src.utils.checkpoint - INFO - Training state restored to step 2273280
2025-08-31 06:02:24,305 - src.core.trainer - INFO - Resumed from step 2273280
2025-08-31 06:02:24,305 - src.core.trainer - INFO - Trainer initialized for experiment: ppo_pendulum_5M
2025-08-31 06:02:24,305 - src.core.trainer - INFO - Experiment directory: experiments/ppo_pendulum_5M_20250831_023506
2025-08-31 06:02:24,307 - src.utils.config - INFO - Configuration saved to experiments/ppo_pendulum_5M_20250831_023506/configs/config.yaml
2025-08-31 06:02:24,318 - src.core.trainer - INFO - Experiment config saved to experiments/ppo_pendulum_5M_20250831_023506/configs/config.yaml
2025-08-31 06:02:24,318 - __main__ - INFO - Experiment directory: experiments/ppo_pendulum_5M_20250831_023506
2025-08-31 06:02:24,318 - __main__ - INFO - Configuration hash: 7514ab70
2025-08-31 06:02:24,318 - __main__ - INFO - Starting training loop...
2025-08-31 06:02:24,318 - src.core.trainer - INFO - Starting training...
2025-08-31 06:02:24,318 - src.core.trainer - INFO - Target steps: 5000000
2025-08-31 06:02:24,318 - src.core.trainer - INFO - Evaluation frequency: 50000
2025-08-31 06:02:24,318 - src.core.trainer - INFO - Checkpoint frequency: 250000
2025-08-31 06:02:25,192 - src.utils.checkpoint - INFO - Checkpoint saved: experiments/ppo_pendulum_5M_20250831_023506/checkpoints/auto_step_2275328.pt (step 2275328)
2025-08-31 06:02:25,196 - src.core.trainer - INFO - Auto-saved checkpoint at step 2275328
2025-08-31 06:02:36,486 - src.utils.logger - INFO - Step 2304000 | train/policy_loss: 0.2850 | train/value_loss: 83358.1098 | train/entropy_loss: -1.4189 | train/total_loss: 58350.8908 | train/grad_norm: 120.5944 | train/debug/update_mean_avg: 0.2915 | train/debug/update_mean_std: 0.0560 | train/debug/update_mean_min: 0.1491 | train/debug/update_mean_max: 0.3598 | train/debug/update_log_std_avg: 1.2656 | train/debug/update_std_avg: 1.0000 | train/debug/update_std_min: 1.0000 | train/debug/update_std_max: 1.0000 | train/debug/update_action_clipped_pct: 0.0000 | train/debug/update_network_output_shape: 2.0000 | train/debug/returns_mean: 2.1691 | train/debug/returns_std: 12.9977 | train/debug/returns_min: -38.8742 | train/debug/returns_max: 40.2178 | train/debug/advantages_mean: 0.0369 | train/debug/advantages_std: 0.9262 | train/debug/advantages_min: -2.6421 | train/debug/advantages_max: 3.2874 | train/debug/old_values_mean: -239.6266 | train/debug/old_values_std: 132.4584 | train/debug/value_error_mean: 243.7192 | train/time_elapsed: 12.1672 | train/steps_per_second: 189361.7204
2025-08-31 06:02:36,490 - src.utils.logger - INFO - Step 2304000 | train/policy_loss: 0.2850 | train/value_loss: 83358.1098 | train/entropy_loss: -1.4189 | train/total_loss: 58350.8908 | train/grad_norm: 120.5944 | train/debug/update_mean_avg: 0.2915 | train/debug/update_mean_std: 0.0560 | train/debug/update_mean_min: 0.1491 | train/debug/update_mean_max: 0.3598 | train/debug/update_log_std_avg: 1.2656 | train/debug/update_std_avg: 1.0000 | train/debug/update_std_min: 1.0000 | train/debug/update_std_max: 1.0000 | train/debug/update_action_clipped_pct: 0.0000 | train/debug/update_network_output_shape: 2.0000 | train/debug/returns_mean: 2.1691 | train/debug/returns_std: 12.9977 | train/debug/returns_min: -38.8742 | train/debug/returns_max: 40.2178 | train/debug/advantages_mean: 0.0369 | train/debug/advantages_std: 0.9262 | train/debug/advantages_min: -2.6421 | train/debug/advantages_max: 3.2874 | train/debug/old_values_mean: -239.6266 | train/debug/old_values_std: 132.4584 | train/debug/value_error_mean: 243.7192 | train/time_elapsed: 12.1720 | train/steps_per_second: 189287.4489
2025-08-31 06:04:07,457 - src.utils.checkpoint - INFO - Checkpoint saved: experiments/ppo_pendulum_5M_20250831_023506/checkpoints/auto_step_2527232.pt (step 2527232)
2025-08-31 06:04:07,462 - src.core.trainer - INFO - Auto-saved checkpoint at step 2527232
2025-08-31 06:04:20,963 - src.utils.logger - INFO - Step 2560000 | train/policy_loss: 0.3086 | train/value_loss: 86.2083 | train/entropy_loss: -1.4189 | train/total_loss: 60.5835 | train/grad_norm: 27.4480 | train/debug/update_mean_avg: 0.2943 | train/debug/update_mean_std: 0.0511 | train/debug/update_mean_min: 0.1968 | train/debug/update_mean_max: 0.3611 | train/debug/update_log_std_avg: 1.2801 | train/debug/update_std_avg: 1.0000 | train/debug/update_std_min: 1.0000 | train/debug/update_std_max: 1.0000 | train/debug/update_action_clipped_pct: 0.0000 | train/debug/update_network_output_shape: 2.0000 | train/debug/returns_mean: 2.1329 | train/debug/returns_std: 9.8076 | train/debug/returns_min: -17.9781 | train/debug/returns_max: 26.3607 | train/debug/advantages_mean: 0.1761 | train/debug/advantages_std: 0.9534 | train/debug/advantages_min: -1.6863 | train/debug/advantages_max: 3.6331 | train/debug/old_values_mean: -0.5263 | train/debug/old_values_std: 5.5190 | train/debug/value_error_mean: 6.5324 | train/time_elapsed: 116.6443 | train/steps_per_second: 21947.0679
2025-08-31 06:04:20,965 - src.utils.logger - INFO - Step 2560000 | train/policy_loss: 0.3086 | train/value_loss: 86.2083 | train/entropy_loss: -1.4189 | train/total_loss: 60.5835 | train/grad_norm: 27.4480 | train/debug/update_mean_avg: 0.2943 | train/debug/update_mean_std: 0.0511 | train/debug/update_mean_min: 0.1968 | train/debug/update_mean_max: 0.3611 | train/debug/update_log_std_avg: 1.2801 | train/debug/update_std_avg: 1.0000 | train/debug/update_std_min: 1.0000 | train/debug/update_std_max: 1.0000 | train/debug/update_action_clipped_pct: 0.0000 | train/debug/update_network_output_shape: 2.0000 | train/debug/returns_mean: 2.1329 | train/debug/returns_std: 9.8076 | train/debug/returns_min: -17.9781 | train/debug/returns_max: 26.3607 | train/debug/advantages_mean: 0.1761 | train/debug/advantages_std: 0.9534 | train/debug/advantages_min: -1.6863 | train/debug/advantages_max: 3.6331 | train/debug/old_values_mean: -0.5263 | train/debug/old_values_std: 5.5190 | train/debug/value_error_mean: 6.5324 | train/time_elapsed: 116.6469 | train/steps_per_second: 21946.5750
2025-08-31 06:05:18,413 - src.core.trainer - INFO - Logging setup complete. Log file: experiments/ppo_pendulum_5M_20250831_023506/logs/training.log
2025-08-31 06:05:18,415 - src.utils.registry - INFO - Registered algorithm: ppo -> PPOAlgorithm
2025-08-31 06:05:18,415 - src.utils.registry - INFO - Registered algorithm: random -> RandomAgent
2025-08-31 06:05:18,417 - src.utils.registry - INFO - Registered network: mlp -> MLP
2025-08-31 06:05:18,417 - src.utils.registry - INFO - Registered network: actor_mlp -> ActorMLP
2025-08-31 06:05:18,417 - src.utils.registry - INFO - Registered network: critic_mlp -> CriticMLP
2025-08-31 06:05:18,417 - src.utils.registry - INFO - Registered network: continuous_actor_mlp -> ContinuousActorMLP
2025-08-31 06:05:18,417 - src.utils.registry - INFO - Registered network: dueling_mlp -> DuelingMLP
2025-08-31 06:05:18,418 - src.utils.registry - INFO - Registered environment: gym -> GymWrapper
2025-08-31 06:05:18,420 - src.utils.registry - INFO - Registered buffer: trajectory -> TrajectoryBuffer
2025-08-31 06:05:18,420 - src.core.trainer - INFO - Initializing environment...
2025-08-31 06:05:18,470 - src.environments.gym_wrapper - INFO - Created Gym environment: Pendulum-v1
2025-08-31 06:05:18,470 - src.core.trainer - INFO - Environment: Pendulum-v1
2025-08-31 06:05:18,471 - src.core.trainer - INFO - Observation space: (3,)
2025-08-31 06:05:18,471 - src.core.trainer - INFO - Action space: (1,), discrete: False
2025-08-31 06:05:18,471 - src.core.trainer - INFO - Initializing networks...
2025-08-31 06:05:18,492 - src.core.trainer - INFO - Created actor network: continuous_actor_mlp
2025-08-31 06:05:18,493 - src.core.trainer - INFO - Created critic network: critic_mlp
2025-08-31 06:05:18,493 - src.core.trainer - INFO - Initializing algorithm...
2025-08-31 06:05:19,144 - src.core.trainer - INFO - Created algorithm: ppo
2025-08-31 06:05:19,144 - src.core.trainer - INFO - Initializing buffer...
2025-08-31 06:05:19,144 - src.core.trainer - INFO - Created buffer: trajectory
2025-08-31 06:05:19,147 - src.environments.gym_wrapper - INFO - Seed will be applied on next reset: 42
2025-08-31 06:05:19,147 - src.core.trainer - INFO - Random seeds set to 42
2025-08-31 06:05:19,147 - src.core.trainer - INFO - All components initialized successfully
2025-08-31 06:05:19,147 - src.utils.checkpoint - INFO - Checkpoint manager initialized at experiments/ppo_pendulum_5M_20250831_023506/checkpoints
2025-08-31 06:05:19,148 - src.utils.logger - INFO - TensorBoard logging enabled: experiments/ppo_pendulum_5M_20250831_023506/tensorboard
2025-08-31 06:05:19,148 - src.utils.logger - INFO - Experiment logger initialized: experiments/ppo_pendulum_5M_20250831_023506
2025-08-31 06:05:19,155 - src.utils.checkpoint - INFO - Checkpoint loaded: experiments/ppo_pendulum_5M_20250831_023506/checkpoints/latest.pt (step 2527232)
2025-08-31 06:05:19,155 - src.core.trainer - INFO - Resuming from checkpoint...
2025-08-31 06:05:19,176 - src.utils.checkpoint - INFO - Training state restored to step 2527232
2025-08-31 06:05:19,177 - src.core.trainer - INFO - Resumed from step 2527232
2025-08-31 06:05:19,177 - src.core.trainer - INFO - Trainer initialized for experiment: ppo_pendulum_5M
2025-08-31 06:05:19,177 - src.core.trainer - INFO - Experiment directory: experiments/ppo_pendulum_5M_20250831_023506
2025-08-31 06:05:19,179 - src.utils.config - INFO - Configuration saved to experiments/ppo_pendulum_5M_20250831_023506/configs/config.yaml
2025-08-31 06:05:19,191 - src.core.trainer - INFO - Experiment config saved to experiments/ppo_pendulum_5M_20250831_023506/configs/config.yaml
2025-08-31 06:05:19,191 - __main__ - INFO - Experiment directory: experiments/ppo_pendulum_5M_20250831_023506
2025-08-31 06:05:19,191 - __main__ - INFO - Configuration hash: f4339465
2025-08-31 06:05:19,191 - __main__ - INFO - Starting training loop...
2025-08-31 06:05:19,191 - src.core.trainer - INFO - Starting training...
2025-08-31 06:05:19,191 - src.core.trainer - INFO - Target steps: 5000000
2025-08-31 06:05:19,191 - src.core.trainer - INFO - Evaluation frequency: 50000
2025-08-31 06:05:19,191 - src.core.trainer - INFO - Checkpoint frequency: 250000
2025-08-31 06:05:20,188 - src.utils.checkpoint - INFO - Checkpoint saved: experiments/ppo_pendulum_5M_20250831_023506/checkpoints/auto_step_2529280.pt (step 2529280)
2025-08-31 06:05:20,189 - src.core.trainer - INFO - Auto-saved checkpoint at step 2529280
2025-08-31 06:05:35,121 - src.utils.logger - INFO - Step 2560000 | train/policy_loss: 0.3007 | train/value_loss: 104351.3641 | train/entropy_loss: -1.4189 | train/total_loss: 73046.1840 | train/grad_norm: 48.4611 | train/debug/update_mean_avg: 0.3028 | train/debug/update_mean_std: 0.0559 | train/debug/update_mean_min: 0.1680 | train/debug/update_mean_max: 0.3611 | train/debug/update_log_std_avg: 1.2823 | train/debug/update_std_avg: 1.0000 | train/debug/update_std_min: 1.0000 | train/debug/update_std_max: 1.0000 | train/debug/update_action_clipped_pct: 0.0000 | train/debug/update_network_output_shape: 2.0000 | train/debug/returns_mean: -336.1328 | train/debug/returns_std: 167.1679 | train/debug/returns_min: -702.7181 | train/debug/returns_max: -4.3203 | train/debug/advantages_mean: 0.0820 | train/debug/advantages_std: 1.0951 | train/debug/advantages_min: -1.9739 | train/debug/advantages_max: 3.7866 | train/debug/old_values_mean: -59.1800 | train/debug/old_values_std: 25.9451 | train/debug/value_error_mean: 280.5732 | train/time_elapsed: 15.9297 | train/steps_per_second: 160705.5984
2025-08-31 06:05:35,125 - src.utils.logger - INFO - Step 2560000 | train/policy_loss: 0.3007 | train/value_loss: 104351.3641 | train/entropy_loss: -1.4189 | train/total_loss: 73046.1840 | train/grad_norm: 48.4611 | train/debug/update_mean_avg: 0.3028 | train/debug/update_mean_std: 0.0559 | train/debug/update_mean_min: 0.1680 | train/debug/update_mean_max: 0.3611 | train/debug/update_log_std_avg: 1.2823 | train/debug/update_std_avg: 1.0000 | train/debug/update_std_min: 1.0000 | train/debug/update_std_max: 1.0000 | train/debug/update_action_clipped_pct: 0.0000 | train/debug/update_network_output_shape: 2.0000 | train/debug/returns_mean: -336.1328 | train/debug/returns_std: 167.1679 | train/debug/returns_min: -702.7181 | train/debug/returns_max: -4.3203 | train/debug/advantages_mean: 0.0820 | train/debug/advantages_std: 1.0951 | train/debug/advantages_min: -1.9739 | train/debug/advantages_max: 3.7866 | train/debug/old_values_mean: -59.1800 | train/debug/old_values_std: 25.9451 | train/debug/value_error_mean: 280.5732 | train/time_elapsed: 15.9334 | train/steps_per_second: 160669.2391
2025-08-31 06:05:54,836 - src.utils.checkpoint - INFO - Checkpoint saved: experiments/ppo_pendulum_5M_20250831_023506/checkpoints/auto_step_2779136.pt (step 2779136)
2025-08-31 06:05:54,838 - src.core.trainer - INFO - Auto-saved checkpoint at step 2779136
2025-08-31 06:06:09,496 - src.utils.logger - INFO - Step 2816000 | train/policy_loss: 0.3161 | train/value_loss: 146.3149 | train/entropy_loss: -1.4189 | train/total_loss: 102.6656 | train/grad_norm: 26.9592 | train/debug/update_mean_avg: 0.2888 | train/debug/update_mean_std: 0.0608 | train/debug/update_mean_min: 0.1321 | train/debug/update_mean_max: 0.3603 | train/debug/update_log_std_avg: 1.2873 | train/debug/update_std_avg: 1.0000 | train/debug/update_std_min: 1.0000 | train/debug/update_std_max: 1.0000 | train/debug/update_action_clipped_pct: 0.0000 | train/debug/update_network_output_shape: 2.0000 | train/debug/returns_mean: 2.4270 | train/debug/returns_std: 13.9719 | train/debug/returns_min: -36.0304 | train/debug/returns_max: 31.9499 | train/debug/advantages_mean: -0.0358 | train/debug/advantages_std: 0.9735 | train/debug/advantages_min: -2.8356 | train/debug/advantages_max: 1.8179 | train/debug/old_values_mean: -2.1579 | train/debug/old_values_std: 6.5218 | train/debug/value_error_mean: 10.0456 | train/time_elapsed: 225.1778 | train/steps_per_second: 12505.6752
2025-08-31 06:06:09,499 - src.utils.logger - INFO - Step 2816000 | train/policy_loss: 0.3161 | train/value_loss: 146.3149 | train/entropy_loss: -1.4189 | train/total_loss: 102.6656 | train/grad_norm: 26.9592 | train/debug/update_mean_avg: 0.2888 | train/debug/update_mean_std: 0.0608 | train/debug/update_mean_min: 0.1321 | train/debug/update_mean_max: 0.3603 | train/debug/update_log_std_avg: 1.2873 | train/debug/update_std_avg: 1.0000 | train/debug/update_std_min: 1.0000 | train/debug/update_std_max: 1.0000 | train/debug/update_action_clipped_pct: 0.0000 | train/debug/update_network_output_shape: 2.0000 | train/debug/returns_mean: 2.4270 | train/debug/returns_std: 13.9719 | train/debug/returns_min: -36.0304 | train/debug/returns_max: 31.9499 | train/debug/advantages_mean: -0.0358 | train/debug/advantages_std: 0.9735 | train/debug/advantages_min: -2.8356 | train/debug/advantages_max: 1.8179 | train/debug/old_values_mean: -2.1579 | train/debug/old_values_std: 6.5218 | train/debug/value_error_mean: 10.0456 | train/time_elapsed: 225.1807 | train/steps_per_second: 12505.5108
