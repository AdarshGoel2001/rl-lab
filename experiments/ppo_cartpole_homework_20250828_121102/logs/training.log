2025-08-28 12:11:02,150 - src.core.trainer - INFO - Logging setup complete. Log file: experiments/ppo_cartpole_homework_20250828_121102/logs/training.log
2025-08-28 12:11:02,152 - src.utils.registry - INFO - Registered network: mlp -> MLP
2025-08-28 12:11:02,152 - src.utils.registry - INFO - Registered network: actor_mlp -> ActorMLP
2025-08-28 12:11:02,152 - src.utils.registry - INFO - Registered network: critic_mlp -> CriticMLP
2025-08-28 12:11:02,152 - src.utils.registry - INFO - Registered network: dueling_mlp -> DuelingMLP
2025-08-28 12:11:02,152 - src.utils.registry - INFO - Registered algorithm: ppo -> PPOAlgorithm
2025-08-28 12:11:02,153 - src.utils.registry - INFO - Registered algorithm: random -> RandomAgent
2025-08-28 12:11:02,154 - src.utils.registry - INFO - Registered environment: gym -> GymWrapper
2025-08-28 12:11:02,155 - src.utils.registry - INFO - Registered buffer: trajectory -> TrajectoryBuffer
2025-08-28 12:11:02,155 - src.core.trainer - INFO - Initializing environment...
2025-08-28 12:11:02,205 - src.environments.gym_wrapper - INFO - Created Gym environment: CartPole-v1
2025-08-28 12:11:02,205 - src.core.trainer - INFO - Environment: CartPole-v1
2025-08-28 12:11:02,205 - src.core.trainer - INFO - Observation space: (4,)
2025-08-28 12:11:02,205 - src.core.trainer - INFO - Action space: (np.int64(2),), discrete: True
2025-08-28 12:11:02,205 - src.core.trainer - INFO - Initializing networks...
2025-08-28 12:11:02,237 - src.core.trainer - INFO - Created actor network: actor_mlp
2025-08-28 12:11:02,238 - src.core.trainer - INFO - Created critic network: critic_mlp
2025-08-28 12:11:02,238 - src.core.trainer - INFO - Initializing algorithm...
2025-08-28 12:11:02,804 - src.core.trainer - INFO - Created algorithm: ppo
2025-08-28 12:11:02,804 - src.core.trainer - INFO - Initializing buffer...
2025-08-28 12:11:02,805 - src.core.trainer - INFO - Created buffer: trajectory
2025-08-28 12:11:02,807 - src.environments.gym_wrapper - INFO - Seed will be applied on next reset: 42
2025-08-28 12:11:02,807 - src.core.trainer - INFO - Random seeds set to 42
2025-08-28 12:11:02,807 - src.core.trainer - INFO - All components initialized successfully
2025-08-28 12:11:02,808 - src.utils.checkpoint - INFO - Checkpoint manager initialized at experiments/ppo_cartpole_homework_20250828_121102/checkpoints
2025-08-28 12:11:02,809 - src.utils.logger - INFO - TensorBoard logging enabled: experiments/ppo_cartpole_homework_20250828_121102/tensorboard
2025-08-28 12:11:04,696 - src.utils.logger - INFO - W&B logging enabled: https://wandb.ai/adarshgoel-rl-lab/rl-lab-homework/runs/rywu2znb
2025-08-28 12:11:04,696 - src.utils.logger - INFO - Experiment logger initialized: experiments/ppo_cartpole_homework_20250828_121102
2025-08-28 12:11:04,696 - src.utils.checkpoint - INFO - No checkpoint found to load
2025-08-28 12:11:04,696 - src.core.trainer - INFO - No checkpoint found, starting from scratch
2025-08-28 12:11:04,696 - src.core.trainer - INFO - Trainer initialized for experiment: ppo_cartpole_homework
2025-08-28 12:11:04,696 - src.core.trainer - INFO - Experiment directory: experiments/ppo_cartpole_homework_20250828_121102
2025-08-28 12:11:04,698 - src.utils.config - INFO - Configuration saved to experiments/ppo_cartpole_homework_20250828_121102/configs/config.yaml
2025-08-28 12:11:04,708 - src.core.trainer - INFO - Experiment config saved to experiments/ppo_cartpole_homework_20250828_121102/configs/config.yaml
2025-08-28 12:11:04,709 - __main__ - INFO - Experiment directory: experiments/ppo_cartpole_homework_20250828_121102
2025-08-28 12:11:04,709 - __main__ - INFO - Configuration hash: 6a1f14ff
2025-08-28 12:11:04,709 - __main__ - INFO - Starting training loop...
2025-08-28 12:11:04,709 - src.core.trainer - INFO - Starting training...
2025-08-28 12:11:04,709 - src.core.trainer - INFO - Target steps: 10000
2025-08-28 12:11:04,709 - src.core.trainer - INFO - Evaluation frequency: 5000
2025-08-28 12:11:04,709 - src.core.trainer - INFO - Checkpoint frequency: 10000
2025-08-28 12:11:06,601 - src.core.trainer - INFO - Running evaluation at step 10000
2025-08-28 12:11:06,810 - src.core.trainer - INFO - Evaluation complete - Mean return: 339.90
2025-08-28 12:11:06,815 - src.utils.checkpoint - INFO - Checkpoint saved: experiments/ppo_cartpole_homework_20250828_121102/checkpoints/auto_step_10000.pt (step 10000)
2025-08-28 12:11:06,815 - src.core.trainer - INFO - Auto-saved checkpoint at step 10000
2025-08-28 12:11:06,815 - src.utils.logger - INFO - Step 10000 | train/policy_loss: -0.0098 | train/value_loss: 1592.0269 | train/entropy_loss: -0.6282 | train/total_loss: 795.9973 | train/grad_norm: 10.3994 | train/time_elapsed: 2.1056 | train/steps_per_second: 4749.1769
2025-08-28 12:11:06,816 - src.utils.logger - INFO - Step 10000 | eval/eval_step: 10000.0000 | eval/eval_episode_count: 10.0000 | eval/eval_return_mean: 339.9000 | eval/eval_return_std: 98.0168 | eval/eval_return_min: 206.0000 | eval/eval_return_max: 500.0000 | eval/eval_length_mean: 339.9000
2025-08-28 12:11:06,817 - src.core.trainer - INFO - Training completed, running final evaluation...
2025-08-28 12:11:06,817 - src.core.trainer - INFO - Running evaluation at step 10000
2025-08-28 12:11:07,079 - src.core.trainer - INFO - Evaluation complete - Mean return: 339.90
2025-08-28 12:11:07,083 - src.utils.checkpoint - INFO - Checkpoint saved: experiments/ppo_cartpole_homework_20250828_121102/checkpoints/final.pt (step 10000)
2025-08-28 12:11:07,083 - src.core.trainer - INFO - Final checkpoint saved: experiments/ppo_cartpole_homework_20250828_121102/checkpoints/final.pt
2025-08-28 12:11:07,083 - src.core.trainer - INFO - Training completed successfully in 2.4s
2025-08-28 12:11:07,088 - src.utils.logger - INFO - TensorBoard writer closed
2025-08-28 12:11:08,512 - src.utils.logger - INFO - W&B run finished
2025-08-28 12:11:08,512 - __main__ - INFO - Training completed successfully!
2025-08-28 12:11:08,512 - __main__ - INFO - Final results:
2025-08-28 12:11:08,512 - __main__ - INFO -   final_step: 10000.0000
2025-08-28 12:11:08,512 - __main__ - INFO -   training_time: 2.3739
2025-08-28 12:11:08,512 - __main__ - INFO -   steps_per_second: 4749.1769
2025-08-28 12:11:08,512 - __main__ - INFO -   policy_loss: -0.0098
2025-08-28 12:11:08,514 - __main__ - INFO -   value_loss: 1592.0269
2025-08-28 12:11:08,515 - __main__ - INFO -   entropy_loss: -0.6282
2025-08-28 12:11:08,515 - __main__ - INFO -   total_loss: 795.9973
2025-08-28 12:11:08,515 - __main__ - INFO -   grad_norm: 10.3994
2025-08-28 12:11:08,515 - __main__ - INFO -   eval_step: 10000.0000
2025-08-28 12:11:08,515 - __main__ - INFO -   eval_episode_count: 10.0000
2025-08-28 12:11:08,515 - __main__ - INFO -   eval_return_mean: 339.9000
2025-08-28 12:11:08,515 - __main__ - INFO -   eval_return_std: 98.0168
2025-08-28 12:11:08,515 - __main__ - INFO -   eval_return_min: 206.0000
2025-08-28 12:11:08,515 - __main__ - INFO -   eval_return_max: 500.0000
2025-08-28 12:11:08,515 - __main__ - INFO -   eval_length_mean: 339.9000
2025-08-28 12:11:08,515 - __main__ - INFO -   time_elapsed: 2.1056
2025-08-28 12:11:08,515 - src.core.trainer - INFO - Trainer cleanup completed
