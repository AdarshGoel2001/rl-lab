2025-08-29 04:54:39,426 - src.core.trainer - INFO - Logging setup complete. Log file: experiments/ppo_acrobot_first_try_20250829_045439/logs/training.log
2025-08-29 04:54:39,429 - src.utils.registry - INFO - Registered network: mlp -> MLP
2025-08-29 04:54:39,429 - src.utils.registry - INFO - Registered network: actor_mlp -> ActorMLP
2025-08-29 04:54:39,429 - src.utils.registry - INFO - Registered network: critic_mlp -> CriticMLP
2025-08-29 04:54:39,429 - src.utils.registry - INFO - Registered network: continuous_actor_mlp -> ContinuousActorMLP
2025-08-29 04:54:39,429 - src.utils.registry - INFO - Registered network: dueling_mlp -> DuelingMLP
2025-08-29 04:54:39,429 - src.utils.registry - INFO - Registered algorithm: ppo -> PPOAlgorithm
2025-08-29 04:54:39,429 - src.utils.registry - INFO - Registered algorithm: random -> RandomAgent
2025-08-29 04:54:39,431 - src.utils.registry - INFO - Registered environment: gym -> GymWrapper
2025-08-29 04:54:39,432 - src.utils.registry - INFO - Registered buffer: trajectory -> TrajectoryBuffer
2025-08-29 04:54:39,432 - src.core.trainer - INFO - Initializing environment...
2025-08-29 04:54:39,474 - src.environments.gym_wrapper - INFO - Created Gym environment: Acrobot-v1
2025-08-29 04:54:39,474 - src.core.trainer - INFO - Environment: Acrobot-v1
2025-08-29 04:54:39,474 - src.core.trainer - INFO - Observation space: (6,)
2025-08-29 04:54:39,474 - src.core.trainer - INFO - Action space: (np.int64(3),), discrete: True
2025-08-29 04:54:39,474 - src.core.trainer - INFO - Initializing networks...
2025-08-29 04:54:39,498 - src.core.trainer - INFO - Created actor network: actor_mlp
2025-08-29 04:54:39,498 - src.core.trainer - INFO - Created critic network: critic_mlp
2025-08-29 04:54:39,499 - src.core.trainer - INFO - Initializing algorithm...
2025-08-29 04:54:40,024 - src.core.trainer - INFO - Created algorithm: ppo
2025-08-29 04:54:40,024 - src.core.trainer - INFO - Initializing buffer...
2025-08-29 04:54:40,024 - src.core.trainer - INFO - Created buffer: trajectory
2025-08-29 04:54:40,026 - src.environments.gym_wrapper - INFO - Seed will be applied on next reset: 42
2025-08-29 04:54:40,026 - src.core.trainer - INFO - Random seeds set to 42
2025-08-29 04:54:40,027 - src.core.trainer - INFO - All components initialized successfully
2025-08-29 04:54:40,027 - src.utils.checkpoint - INFO - Checkpoint manager initialized at experiments/ppo_acrobot_first_try_20250829_045439/checkpoints
2025-08-29 04:54:40,028 - src.utils.logger - INFO - TensorBoard logging enabled: experiments/ppo_acrobot_first_try_20250829_045439/tensorboard
2025-08-29 04:54:40,028 - src.utils.logger - INFO - Experiment logger initialized: experiments/ppo_acrobot_first_try_20250829_045439
2025-08-29 04:54:40,028 - src.utils.checkpoint - INFO - No checkpoint found to load
2025-08-29 04:54:40,028 - src.core.trainer - INFO - No checkpoint found, starting from scratch
2025-08-29 04:54:40,028 - src.core.trainer - INFO - Trainer initialized for experiment: ppo_acrobot_first_try
2025-08-29 04:54:40,028 - src.core.trainer - INFO - Experiment directory: experiments/ppo_acrobot_first_try_20250829_045439
2025-08-29 04:54:40,030 - src.utils.config - INFO - Configuration saved to experiments/ppo_acrobot_first_try_20250829_045439/configs/config.yaml
2025-08-29 04:54:40,038 - src.core.trainer - INFO - Experiment config saved to experiments/ppo_acrobot_first_try_20250829_045439/configs/config.yaml
2025-08-29 04:54:40,038 - __main__ - INFO - Experiment directory: experiments/ppo_acrobot_first_try_20250829_045439
2025-08-29 04:54:40,039 - __main__ - INFO - Configuration hash: aad666b2
2025-08-29 04:54:40,039 - __main__ - INFO - Starting training loop...
2025-08-29 04:54:40,039 - src.core.trainer - INFO - Starting training...
2025-08-29 04:54:40,039 - src.core.trainer - INFO - Target steps: 150000
2025-08-29 04:54:40,039 - src.core.trainer - INFO - Evaluation frequency: 10000
2025-08-29 04:54:40,039 - src.core.trainer - INFO - Checkpoint frequency: 25000
2025-08-29 04:54:46,052 - src.utils.checkpoint - INFO - Checkpoint saved: experiments/ppo_acrobot_first_try_20250829_045439/checkpoints/auto_step_28672.pt (step 28672)
2025-08-29 04:54:46,053 - src.core.trainer - INFO - Auto-saved checkpoint at step 28672
2025-08-29 04:54:51,982 - src.utils.checkpoint - INFO - Checkpoint saved: experiments/ppo_acrobot_first_try_20250829_045439/checkpoints/auto_step_57344.pt (step 57344)
2025-08-29 04:54:51,983 - src.core.trainer - INFO - Auto-saved checkpoint at step 57344
2025-08-29 04:54:57,880 - src.utils.checkpoint - INFO - Checkpoint saved: experiments/ppo_acrobot_first_try_20250829_045439/checkpoints/auto_step_86016.pt (step 86016)
2025-08-29 04:54:57,880 - src.core.trainer - INFO - Auto-saved checkpoint at step 86016
2025-08-29 04:55:03,861 - src.utils.checkpoint - INFO - Checkpoint saved: experiments/ppo_acrobot_first_try_20250829_045439/checkpoints/auto_step_114688.pt (step 114688)
2025-08-29 04:55:03,861 - src.core.trainer - INFO - Auto-saved checkpoint at step 114688
2025-08-29 04:55:09,791 - src.utils.checkpoint - INFO - Checkpoint saved: experiments/ppo_acrobot_first_try_20250829_045439/checkpoints/auto_step_143360.pt (step 143360)
2025-08-29 04:55:09,791 - src.core.trainer - INFO - Auto-saved checkpoint at step 143360
2025-08-29 04:55:11,068 - src.core.trainer - INFO - Running evaluation at step 150000
2025-08-29 04:55:11,159 - src.core.trainer - INFO - Evaluation complete - Mean return: -82.70
2025-08-29 04:55:11,159 - src.utils.logger - INFO - Step 150000 | train/policy_loss: 0.0015 | train/value_loss: 221.3979 | train/entropy_loss: -0.7121 | train/total_loss: 110.6648 | train/grad_norm: 14.5676 | train/time_elapsed: 31.1202 | train/steps_per_second: 4820.0248
2025-08-29 04:55:11,160 - src.utils.logger - INFO - Step 150000 | eval/eval_step: 150000.0000 | eval/eval_episode_count: 10.0000 | eval/eval_return_mean: -82.7000 | eval/eval_return_std: 16.6916 | eval/eval_return_min: -110.0000 | eval/eval_return_max: -63.0000 | eval/eval_length_mean: 83.7000
2025-08-29 04:55:11,161 - src.core.trainer - INFO - Training completed, running final evaluation...
2025-08-29 04:55:11,161 - src.core.trainer - INFO - Running evaluation at step 150000
2025-08-29 04:55:11,251 - src.core.trainer - INFO - Evaluation complete - Mean return: -82.70
2025-08-29 04:55:11,255 - src.utils.checkpoint - INFO - Checkpoint saved: experiments/ppo_acrobot_first_try_20250829_045439/checkpoints/final.pt (step 150000)
2025-08-29 04:55:11,256 - src.core.trainer - INFO - Final checkpoint saved: experiments/ppo_acrobot_first_try_20250829_045439/checkpoints/final.pt
2025-08-29 04:55:11,256 - src.core.trainer - INFO - Training completed successfully in 31.2s
2025-08-29 04:55:11,260 - src.utils.logger - INFO - TensorBoard writer closed
2025-08-29 04:55:11,260 - __main__ - INFO - Training completed successfully!
2025-08-29 04:55:11,260 - __main__ - INFO - Final results:
2025-08-29 04:55:11,260 - __main__ - INFO -   final_step: 150000.0000
2025-08-29 04:55:11,261 - __main__ - INFO -   training_time: 31.2172
2025-08-29 04:55:11,261 - __main__ - INFO -   steps_per_second: 4820.0248
2025-08-29 04:55:11,261 - __main__ - INFO -   policy_loss: 0.0015
2025-08-29 04:55:11,261 - __main__ - INFO -   value_loss: 221.3979
2025-08-29 04:55:11,261 - __main__ - INFO -   entropy_loss: -0.7121
2025-08-29 04:55:11,261 - __main__ - INFO -   total_loss: 110.6648
2025-08-29 04:55:11,261 - __main__ - INFO -   grad_norm: 14.5676
2025-08-29 04:55:11,261 - __main__ - INFO -   eval_step: 150000.0000
2025-08-29 04:55:11,261 - __main__ - INFO -   eval_episode_count: 10.0000
2025-08-29 04:55:11,261 - __main__ - INFO -   eval_return_mean: -82.7000
2025-08-29 04:55:11,261 - __main__ - INFO -   eval_return_std: 16.6916
2025-08-29 04:55:11,261 - __main__ - INFO -   eval_return_min: -110.0000
2025-08-29 04:55:11,261 - __main__ - INFO -   eval_return_max: -63.0000
2025-08-29 04:55:11,261 - __main__ - INFO -   eval_length_mean: 83.7000
2025-08-29 04:55:11,261 - __main__ - INFO -   time_elapsed: 31.1202
2025-08-29 04:55:11,261 - src.core.trainer - INFO - Trainer cleanup completed
