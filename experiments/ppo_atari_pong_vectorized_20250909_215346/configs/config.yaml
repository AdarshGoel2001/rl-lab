algorithm:
  lr: 0.00025
  name: ppo
buffer:
  batch_size: 256
  capacity: 128
  type: trajectory
environment:
  max_episode_steps: null
  name: ALE/Pong-v5
  normalize_obs: false
  normalize_reward: false
  wrapper: vectorized_gym
evaluation:
  max_episode_steps: null
  name: ALE/Pong-v5
  normalize_obs: false
  normalize_reward: false
  wrapper: gym
experiment:
  debug: false
  device: cpu
  name: ppo_atari_pong_vectorized
  seed: 42
logging:
  log_frequency: 10000
  tensorboard: true
  terminal: true
  wandb_enabled: false
  wandb_project: null
  wandb_tags: []
network:
  actor:
    activation: relu
    hidden_dims:
    - 64
    - 64
    initialization: xavier_uniform
    input_dim: null
    output_activation: linear
    output_dim: null
    type: nature_cnn
  critic:
    activation: relu
    hidden_dims:
    - 64
    - 64
    initialization: xavier_uniform
    input_dim: null
    output_activation: linear
    output_dim: null
    type: nature_cnn
training:
  checkpoint_frequency: 500000
  eval_frequency: 100000
  num_eval_episodes: 10
  total_timesteps: 10000000
