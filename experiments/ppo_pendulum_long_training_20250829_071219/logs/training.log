2025-08-29 07:12:19,264 - src.core.trainer - INFO - Logging setup complete. Log file: experiments/ppo_pendulum_long_training_20250829_071219/logs/training.log
2025-08-29 07:12:19,266 - src.utils.registry - INFO - Registered algorithm: ppo -> PPOAlgorithm
2025-08-29 07:12:19,266 - src.utils.registry - INFO - Registered algorithm: random -> RandomAgent
2025-08-29 07:12:19,267 - src.utils.registry - INFO - Registered network: mlp -> MLP
2025-08-29 07:12:19,267 - src.utils.registry - INFO - Registered network: actor_mlp -> ActorMLP
2025-08-29 07:12:19,267 - src.utils.registry - INFO - Registered network: critic_mlp -> CriticMLP
2025-08-29 07:12:19,267 - src.utils.registry - INFO - Registered network: continuous_actor_mlp -> ContinuousActorMLP
2025-08-29 07:12:19,267 - src.utils.registry - INFO - Registered network: dueling_mlp -> DuelingMLP
2025-08-29 07:12:19,269 - src.utils.registry - INFO - Registered environment: gym -> GymWrapper
2025-08-29 07:12:19,270 - src.utils.registry - INFO - Registered buffer: trajectory -> TrajectoryBuffer
2025-08-29 07:12:19,270 - src.core.trainer - INFO - Initializing environment...
2025-08-29 07:12:19,317 - src.environments.gym_wrapper - INFO - Created Gym environment: Pendulum-v1
2025-08-29 07:12:19,317 - src.core.trainer - INFO - Environment: Pendulum-v1
2025-08-29 07:12:19,317 - src.core.trainer - INFO - Observation space: (3,)
2025-08-29 07:12:19,317 - src.core.trainer - INFO - Action space: (1,), discrete: False
2025-08-29 07:12:19,317 - src.core.trainer - INFO - Initializing networks...
2025-08-29 07:12:19,363 - src.core.trainer - INFO - Created actor network: continuous_actor_mlp
2025-08-29 07:12:19,364 - src.core.trainer - INFO - Created critic network: critic_mlp
2025-08-29 07:12:19,364 - src.core.trainer - INFO - Initializing algorithm...
2025-08-29 07:12:19,936 - src.core.trainer - INFO - Created algorithm: ppo
2025-08-29 07:12:19,936 - src.core.trainer - INFO - Initializing buffer...
2025-08-29 07:12:19,936 - src.core.trainer - INFO - Created buffer: trajectory
2025-08-29 07:12:19,939 - src.environments.gym_wrapper - INFO - Seed will be applied on next reset: 42
2025-08-29 07:12:19,939 - src.core.trainer - INFO - Random seeds set to 42
2025-08-29 07:12:19,939 - src.core.trainer - INFO - All components initialized successfully
2025-08-29 07:12:19,939 - src.utils.checkpoint - INFO - Checkpoint manager initialized at experiments/ppo_pendulum_long_training_20250829_071219/checkpoints
2025-08-29 07:12:19,940 - src.utils.logger - INFO - TensorBoard logging enabled: experiments/ppo_pendulum_long_training_20250829_071219/tensorboard
2025-08-29 07:12:19,940 - src.utils.logger - INFO - Experiment logger initialized: experiments/ppo_pendulum_long_training_20250829_071219
2025-08-29 07:12:19,940 - src.utils.checkpoint - INFO - No checkpoint found to load
2025-08-29 07:12:19,941 - src.core.trainer - INFO - No checkpoint found, starting from scratch
2025-08-29 07:12:19,941 - src.core.trainer - INFO - Trainer initialized for experiment: ppo_pendulum_long_training
2025-08-29 07:12:19,941 - src.core.trainer - INFO - Experiment directory: experiments/ppo_pendulum_long_training_20250829_071219
2025-08-29 07:12:19,943 - src.utils.config - INFO - Configuration saved to experiments/ppo_pendulum_long_training_20250829_071219/configs/config.yaml
2025-08-29 07:12:19,952 - src.core.trainer - INFO - Experiment config saved to experiments/ppo_pendulum_long_training_20250829_071219/configs/config.yaml
2025-08-29 07:12:19,952 - __main__ - INFO - Experiment directory: experiments/ppo_pendulum_long_training_20250829_071219
2025-08-29 07:12:19,952 - __main__ - INFO - Configuration hash: 351bd33a
2025-08-29 07:12:19,952 - __main__ - INFO - Starting training loop...
2025-08-29 07:12:19,952 - src.core.trainer - INFO - Starting training...
2025-08-29 07:12:19,952 - src.core.trainer - INFO - Target steps: 2000000
2025-08-29 07:12:19,952 - src.core.trainer - INFO - Evaluation frequency: 25000
2025-08-29 07:12:19,952 - src.core.trainer - INFO - Checkpoint frequency: 100000
2025-08-29 07:12:49,334 - src.utils.checkpoint - INFO - Checkpoint saved: experiments/ppo_pendulum_long_training_20250829_071219/checkpoints/auto_step_100352.pt (step 100352)
2025-08-29 07:12:49,334 - src.core.trainer - INFO - Auto-saved checkpoint at step 100352
2025-08-29 07:13:18,573 - src.utils.checkpoint - INFO - Checkpoint saved: experiments/ppo_pendulum_long_training_20250829_071219/checkpoints/auto_step_200704.pt (step 200704)
2025-08-29 07:13:18,574 - src.core.trainer - INFO - Auto-saved checkpoint at step 200704
2025-08-29 07:13:35,849 - src.utils.logger - INFO - Step 256000 | train/policy_loss: 0.3231 | train/value_loss: 132132.1959 | train/entropy_loss: -0.9189 | train/total_loss: 66066.3741 | train/grad_norm: 58.9906 | train/debug/update_mean_avg: 0.4817 | train/debug/update_mean_std: 0.0076 | train/debug/update_mean_min: 0.4552 | train/debug/update_mean_max: 0.4902 | train/debug/update_log_std_avg: 1.6132 | train/debug/update_std_avg: 0.6065 | train/debug/update_std_min: 0.6065 | train/debug/update_std_max: 0.6065 | train/debug/update_action_clipped_pct: 0.0000 | train/debug/update_network_output_shape: 2.0000 | train/debug/returns_mean: -386.3464 | train/debug/returns_std: 192.6658 | train/debug/returns_min: -729.8428 | train/debug/returns_max: -21.9783 | train/debug/advantages_mean: 0.0198 | train/debug/advantages_std: 1.0637 | train/debug/advantages_min: -1.2788 | train/debug/advantages_max: 3.5616 | train/debug/old_values_mean: -86.6205 | train/debug/old_values_std: 0.0000 | train/debug/value_error_mean: 306.7142 | train/time_elapsed: 75.8963 | train/steps_per_second: 3373.0253
2025-08-29 07:13:35,851 - src.utils.logger - INFO - Step 256000 | train/policy_loss: 0.3231 | train/value_loss: 132132.1959 | train/entropy_loss: -0.9189 | train/total_loss: 66066.3741 | train/grad_norm: 58.9906 | train/debug/update_mean_avg: 0.4817 | train/debug/update_mean_std: 0.0076 | train/debug/update_mean_min: 0.4552 | train/debug/update_mean_max: 0.4902 | train/debug/update_log_std_avg: 1.6132 | train/debug/update_std_avg: 0.6065 | train/debug/update_std_min: 0.6065 | train/debug/update_std_max: 0.6065 | train/debug/update_action_clipped_pct: 0.0000 | train/debug/update_network_output_shape: 2.0000 | train/debug/returns_mean: -386.3464 | train/debug/returns_std: 192.6658 | train/debug/returns_min: -729.8428 | train/debug/returns_max: -21.9783 | train/debug/advantages_mean: 0.0198 | train/debug/advantages_std: 1.0637 | train/debug/advantages_min: -1.2788 | train/debug/advantages_max: 3.5616 | train/debug/old_values_mean: -86.6205 | train/debug/old_values_std: 0.0000 | train/debug/value_error_mean: 306.7142 | train/time_elapsed: 75.8985 | train/steps_per_second: 3372.9238
2025-08-29 07:13:49,324 - src.utils.checkpoint - INFO - Checkpoint saved: experiments/ppo_pendulum_long_training_20250829_071219/checkpoints/auto_step_301056.pt (step 301056)
2025-08-29 07:13:49,324 - src.core.trainer - INFO - Auto-saved checkpoint at step 301056
2025-08-29 07:14:18,826 - src.utils.checkpoint - INFO - Checkpoint saved: experiments/ppo_pendulum_long_training_20250829_071219/checkpoints/auto_step_401408.pt (step 401408)
2025-08-29 07:14:18,826 - src.core.trainer - INFO - Auto-saved checkpoint at step 401408
2025-08-29 07:14:48,426 - src.utils.checkpoint - INFO - Checkpoint saved: experiments/ppo_pendulum_long_training_20250829_071219/checkpoints/auto_step_501760.pt (step 501760)
2025-08-29 07:14:48,427 - src.core.trainer - INFO - Auto-saved checkpoint at step 501760
2025-08-29 07:14:51,403 - src.utils.logger - INFO - Step 512000 | train/policy_loss: 0.3109 | train/value_loss: 53785.9665 | train/entropy_loss: -0.9189 | train/total_loss: 26893.2473 | train/grad_norm: 33.2655 | train/debug/update_mean_avg: 0.4748 | train/debug/update_mean_std: 0.0121 | train/debug/update_mean_min: 0.4483 | train/debug/update_mean_max: 0.4895 | train/debug/update_log_std_avg: 1.5812 | train/debug/update_std_avg: 0.6065 | train/debug/update_std_min: 0.6065 | train/debug/update_std_max: 0.6065 | train/debug/update_action_clipped_pct: 0.0000 | train/debug/update_network_output_shape: 2.0000 | train/debug/returns_mean: -339.5957 | train/debug/returns_std: 140.4675 | train/debug/returns_min: -620.0784 | train/debug/returns_max: -42.5866 | train/debug/advantages_mean: -0.1042 | train/debug/advantages_std: 0.9060 | train/debug/advantages_min: -1.0380 | train/debug/advantages_max: 3.3339 | train/debug/old_values_mean: -164.3211 | train/debug/old_values_std: 0.0000 | train/debug/value_error_mean: 195.2187 | train/time_elapsed: 151.4502 | train/steps_per_second: 3380.6497
2025-08-29 07:14:51,405 - src.utils.logger - INFO - Step 512000 | train/policy_loss: 0.3109 | train/value_loss: 53785.9665 | train/entropy_loss: -0.9189 | train/total_loss: 26893.2473 | train/grad_norm: 33.2655 | train/debug/update_mean_avg: 0.4748 | train/debug/update_mean_std: 0.0121 | train/debug/update_mean_min: 0.4483 | train/debug/update_mean_max: 0.4895 | train/debug/update_log_std_avg: 1.5812 | train/debug/update_std_avg: 0.6065 | train/debug/update_std_min: 0.6065 | train/debug/update_std_max: 0.6065 | train/debug/update_action_clipped_pct: 0.0000 | train/debug/update_network_output_shape: 2.0000 | train/debug/returns_mean: -339.5957 | train/debug/returns_std: 140.4675 | train/debug/returns_min: -620.0784 | train/debug/returns_max: -42.5866 | train/debug/advantages_mean: -0.1042 | train/debug/advantages_std: 0.9060 | train/debug/advantages_min: -1.0380 | train/debug/advantages_max: 3.3339 | train/debug/old_values_mean: -164.3211 | train/debug/old_values_std: 0.0000 | train/debug/value_error_mean: 195.2187 | train/time_elapsed: 151.4521 | train/steps_per_second: 3380.6064
2025-08-29 07:15:18,171 - src.utils.checkpoint - INFO - Checkpoint saved: experiments/ppo_pendulum_long_training_20250829_071219/checkpoints/auto_step_602112.pt (step 602112)
2025-08-29 07:15:18,175 - src.core.trainer - INFO - Auto-saved checkpoint at step 602112
2025-08-29 07:15:48,012 - src.utils.checkpoint - INFO - Checkpoint saved: experiments/ppo_pendulum_long_training_20250829_071219/checkpoints/auto_step_702464.pt (step 702464)
2025-08-29 07:15:48,014 - src.core.trainer - INFO - Auto-saved checkpoint at step 702464
2025-08-29 07:16:07,097 - src.utils.logger - INFO - Step 768000 | train/policy_loss: 0.3035 | train/value_loss: 35969.0634 | train/entropy_loss: -0.9189 | train/total_loss: 17984.7886 | train/grad_norm: 24.6786 | train/debug/update_mean_avg: 0.4738 | train/debug/update_mean_std: 0.0128 | train/debug/update_mean_min: 0.4498 | train/debug/update_mean_max: 0.4900 | train/debug/update_log_std_avg: 1.5795 | train/debug/update_std_avg: 0.6065 | train/debug/update_std_min: 0.6065 | train/debug/update_std_max: 0.6065 | train/debug/update_action_clipped_pct: 0.0000 | train/debug/update_network_output_shape: 2.0000 | train/debug/returns_mean: -324.6295 | train/debug/returns_std: 157.8947 | train/debug/returns_min: -643.2864 | train/debug/returns_max: -4.3553 | train/debug/advantages_mean: 0.1058 | train/debug/advantages_std: 0.9497 | train/debug/advantages_min: -0.8516 | train/debug/advantages_max: 3.1730 | train/debug/old_values_mean: -242.0221 | train/debug/old_values_std: 0.0000 | train/debug/value_error_mean: 154.0654 | train/time_elapsed: 227.1443 | train/steps_per_second: 3381.1105
2025-08-29 07:16:07,100 - src.utils.logger - INFO - Step 768000 | train/policy_loss: 0.3035 | train/value_loss: 35969.0634 | train/entropy_loss: -0.9189 | train/total_loss: 17984.7886 | train/grad_norm: 24.6786 | train/debug/update_mean_avg: 0.4738 | train/debug/update_mean_std: 0.0128 | train/debug/update_mean_min: 0.4498 | train/debug/update_mean_max: 0.4900 | train/debug/update_log_std_avg: 1.5795 | train/debug/update_std_avg: 0.6065 | train/debug/update_std_min: 0.6065 | train/debug/update_std_max: 0.6065 | train/debug/update_action_clipped_pct: 0.0000 | train/debug/update_network_output_shape: 2.0000 | train/debug/returns_mean: -324.6295 | train/debug/returns_std: 157.8947 | train/debug/returns_min: -643.2864 | train/debug/returns_max: -4.3553 | train/debug/advantages_mean: 0.1058 | train/debug/advantages_std: 0.9497 | train/debug/advantages_min: -0.8516 | train/debug/advantages_max: 3.1730 | train/debug/old_values_mean: -242.0221 | train/debug/old_values_std: 0.0000 | train/debug/value_error_mean: 154.0654 | train/time_elapsed: 227.1472 | train/steps_per_second: 3381.0674
2025-08-29 07:16:17,362 - src.utils.checkpoint - INFO - Checkpoint saved: experiments/ppo_pendulum_long_training_20250829_071219/checkpoints/auto_step_802816.pt (step 802816)
2025-08-29 07:16:17,362 - src.core.trainer - INFO - Auto-saved checkpoint at step 802816
2025-08-29 07:17:48,474 - src.core.trainer - INFO - Logging setup complete. Log file: experiments/ppo_pendulum_long_training_20250829_071219/logs/training.log
2025-08-29 07:17:48,477 - src.utils.registry - INFO - Registered algorithm: ppo -> PPOAlgorithm
2025-08-29 07:17:48,477 - src.utils.registry - INFO - Registered algorithm: random -> RandomAgent
2025-08-29 07:17:48,478 - src.utils.registry - INFO - Registered network: mlp -> MLP
2025-08-29 07:17:48,478 - src.utils.registry - INFO - Registered network: actor_mlp -> ActorMLP
2025-08-29 07:17:48,478 - src.utils.registry - INFO - Registered network: critic_mlp -> CriticMLP
2025-08-29 07:17:48,478 - src.utils.registry - INFO - Registered network: continuous_actor_mlp -> ContinuousActorMLP
2025-08-29 07:17:48,478 - src.utils.registry - INFO - Registered network: dueling_mlp -> DuelingMLP
2025-08-29 07:17:48,479 - src.utils.registry - INFO - Registered environment: gym -> GymWrapper
2025-08-29 07:17:48,480 - src.utils.registry - INFO - Registered buffer: trajectory -> TrajectoryBuffer
2025-08-29 07:17:48,480 - src.core.trainer - INFO - Initializing environment...
2025-08-29 07:17:48,529 - src.environments.gym_wrapper - INFO - Created Gym environment: Pendulum-v1
2025-08-29 07:17:48,530 - src.core.trainer - INFO - Environment: Pendulum-v1
2025-08-29 07:17:48,530 - src.core.trainer - INFO - Observation space: (3,)
2025-08-29 07:17:48,530 - src.core.trainer - INFO - Action space: (1,), discrete: False
2025-08-29 07:17:48,530 - src.core.trainer - INFO - Initializing networks...
2025-08-29 07:17:48,569 - src.core.trainer - INFO - Created actor network: continuous_actor_mlp
2025-08-29 07:17:48,570 - src.core.trainer - INFO - Created critic network: critic_mlp
2025-08-29 07:17:48,570 - src.core.trainer - INFO - Initializing algorithm...
2025-08-29 07:17:49,137 - src.core.trainer - INFO - Created algorithm: ppo
2025-08-29 07:17:49,137 - src.core.trainer - INFO - Initializing buffer...
2025-08-29 07:17:49,137 - src.core.trainer - INFO - Created buffer: trajectory
2025-08-29 07:17:49,140 - src.environments.gym_wrapper - INFO - Seed will be applied on next reset: 42
2025-08-29 07:17:49,140 - src.core.trainer - INFO - Random seeds set to 42
2025-08-29 07:17:49,140 - src.core.trainer - INFO - All components initialized successfully
2025-08-29 07:17:49,140 - src.utils.checkpoint - INFO - Checkpoint manager initialized at experiments/ppo_pendulum_long_training_20250829_071219/checkpoints
2025-08-29 07:17:49,141 - src.utils.logger - INFO - TensorBoard logging enabled: experiments/ppo_pendulum_long_training_20250829_071219/tensorboard
2025-08-29 07:17:49,141 - src.utils.logger - INFO - Experiment logger initialized: experiments/ppo_pendulum_long_training_20250829_071219
2025-08-29 07:17:49,149 - src.utils.checkpoint - INFO - Checkpoint loaded: experiments/ppo_pendulum_long_training_20250829_071219/checkpoints/latest.pt (step 802816)
2025-08-29 07:17:49,149 - src.core.trainer - INFO - Resuming from checkpoint...
2025-08-29 07:17:49,150 - src.utils.checkpoint - INFO - Training state restored to step 802816
2025-08-29 07:17:49,150 - src.core.trainer - INFO - Resumed from step 802816
2025-08-29 07:17:49,150 - src.core.trainer - INFO - Trainer initialized for experiment: ppo_pendulum_long_training
2025-08-29 07:17:49,150 - src.core.trainer - INFO - Experiment directory: experiments/ppo_pendulum_long_training_20250829_071219
2025-08-29 07:17:49,152 - src.utils.config - INFO - Configuration saved to experiments/ppo_pendulum_long_training_20250829_071219/configs/config.yaml
2025-08-29 07:17:49,161 - src.core.trainer - INFO - Experiment config saved to experiments/ppo_pendulum_long_training_20250829_071219/configs/config.yaml
2025-08-29 07:17:49,161 - __main__ - INFO - Experiment directory: experiments/ppo_pendulum_long_training_20250829_071219
2025-08-29 07:17:49,162 - __main__ - INFO - Configuration hash: 351bd33a
2025-08-29 07:17:49,162 - __main__ - INFO - Starting training loop...
2025-08-29 07:17:49,162 - src.core.trainer - INFO - Starting training...
2025-08-29 07:17:49,162 - src.core.trainer - INFO - Target steps: 2000000
2025-08-29 07:17:49,162 - src.core.trainer - INFO - Evaluation frequency: 25000
2025-08-29 07:17:49,162 - src.core.trainer - INFO - Checkpoint frequency: 100000
2025-08-29 07:17:49,825 - src.utils.checkpoint - INFO - Checkpoint saved: experiments/ppo_pendulum_long_training_20250829_071219/checkpoints/auto_step_804864.pt (step 804864)
2025-08-29 07:17:49,830 - src.core.trainer - INFO - Auto-saved checkpoint at step 804864
2025-08-29 07:18:19,702 - src.utils.checkpoint - INFO - Checkpoint saved: experiments/ppo_pendulum_long_training_20250829_071219/checkpoints/auto_step_905216.pt (step 905216)
2025-08-29 07:18:19,708 - src.core.trainer - INFO - Auto-saved checkpoint at step 905216
2025-08-29 07:18:50,188 - src.utils.checkpoint - INFO - Checkpoint saved: experiments/ppo_pendulum_long_training_20250829_071219/checkpoints/auto_step_1005568.pt (step 1005568)
2025-08-29 07:18:50,189 - src.core.trainer - INFO - Auto-saved checkpoint at step 1005568
2025-08-29 07:18:55,939 - src.utils.logger - INFO - Step 1024000 | train/policy_loss: 0.2991 | train/value_loss: 30704.8349 | train/entropy_loss: -3.4189 | train/total_loss: 15352.5453 | train/grad_norm: 319.0748 | train/time_elapsed: 66.7776 | train/steps_per_second: 15334.4768
2025-08-29 07:18:55,940 - src.utils.logger - INFO - Step 1024000 | train/policy_loss: 0.2991 | train/value_loss: 30704.8349 | train/entropy_loss: -3.4189 | train/total_loss: 15352.5453 | train/grad_norm: 319.0748 | train/debug/update_mean_avg: 0.4775 | train/debug/update_mean_std: 0.0101 | train/debug/update_mean_min: 0.4486 | train/debug/update_mean_max: 0.4897 | train/debug/update_log_std_avg: 1.5916 | train/debug/update_std_avg: 0.6065 | train/debug/update_std_min: 0.6065 | train/debug/update_std_max: 0.6065 | train/debug/update_action_clipped_pct: 0.0000 | train/debug/update_network_output_shape: 2.0000 | train/debug/returns_mean: -376.2545 | train/debug/returns_std: 166.6305 | train/debug/returns_min: -709.0049 | train/debug/returns_max: -6.4568 | train/debug/advantages_mean: -0.0790 | train/debug/advantages_std: 0.8395 | train/debug/advantages_min: -0.9361 | train/debug/advantages_max: 4.4864 | train/debug/old_values_mean: -252.5895 | train/debug/old_values_std: 0.0000 | train/debug/value_error_mean: 175.3900 | train/time_elapsed: 66.7785 | train/steps_per_second: 15334.2731
2025-08-29 07:19:21,283 - src.utils.checkpoint - INFO - Checkpoint saved: experiments/ppo_pendulum_long_training_20250829_071219/checkpoints/auto_step_1105920.pt (step 1105920)
2025-08-29 07:19:21,286 - src.core.trainer - INFO - Auto-saved checkpoint at step 1105920
