_wandb:
    value:
        cli_version: 0.21.1
        e:
            mxm9z75rdh6yy0r1oywkg8gn8glvn2jq:
                args:
                    - --config
                    - configs/experiments/ppo_cartpole.yaml
                    - --total-timesteps
                    - "2000"
                    - --name
                    - system_test
                codePath: scripts/train.py
                codePathLocal: scripts/train.py
                email: adarshgoel@gmail.com
                executable: /Users/martian/miniconda3/envs/rl-lab/bin/python
                git:
                    commit: 3d7d3b433d0f8293dab66d7ca1471a2a4d26e55a
                    remote: git@github.com:AdarshGoel2001/rl-lab.git
                host: Adarshs-MacBook-Pro.local
                os: macOS-15.6.1-arm64-arm-64bit
                program: /Users/martian/Documents/Code/rl-lab/scripts/train.py
                python: CPython 3.10.18
                root: experiments/system_test_20250828_131746
                startedAt: "2025-08-28T07:47:47.660997Z"
                writerId: mxm9z75rdh6yy0r1oywkg8gn8glvn2jq
        m: []
        python_version: 3.10.18
        t:
            "1":
                - 1
            "2":
                - 1
            "3":
                - 2
                - 13
                - 15
                - 16
            "4": 3.10.18
            "5": 0.21.1
            "12": 0.21.1
            "13": darwin-arm64
algorithm.lr:
    value: "3e-4"
algorithm.name:
    value: ppo
buffer.batch_size:
    value: 2048
buffer.capacity:
    value: 2048
buffer.type:
    value: trajectory
environment.max_episode_steps:
    value: 500
environment.name:
    value: CartPole-v1
environment.normalize_obs:
    value: false
environment.normalize_reward:
    value: false
environment.wrapper:
    value: gym
experiment.debug:
    value: true
experiment.device:
    value: cpu
experiment.name:
    value: system_test
experiment.seed:
    value: 42
logging.log_frequency:
    value: 1000
logging.tensorboard:
    value: true
logging.terminal:
    value: true
logging.wandb_enabled:
    value: true
logging.wandb_project:
    value: null
logging.wandb_tags:
    value: '[]'
network.actor.activation:
    value: tanh
network.actor.hidden_dims:
    value: '[64, 64]'
network.actor.initialization:
    value: xavier_uniform
network.actor.input_dim:
    value: null
network.actor.output_activation:
    value: linear
network.actor.output_dim:
    value: null
network.actor.type:
    value: actor_mlp
network.critic.activation:
    value: tanh
network.critic.hidden_dims:
    value: '[64, 64]'
network.critic.initialization:
    value: xavier_uniform
network.critic.input_dim:
    value: null
network.critic.output_activation:
    value: linear
network.critic.output_dim:
    value: null
network.critic.type:
    value: critic_mlp
training.checkpoint_frequency:
    value: 10000
training.eval_frequency:
    value: 5000
training.num_eval_episodes:
    value: 10
training.total_timesteps:
    value: 2000
