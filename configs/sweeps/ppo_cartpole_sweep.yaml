# PPO CartPole Hyperparameter Sweep Configuration
#
# This sweep configuration demonstrates how to optimize PPO hyperparameters
# for the CartPole environment using Optuna's advanced optimization algorithms.
#
# Usage:
# python scripts/sweep.py --config configs/sweeps/ppo_cartpole_sweep.yaml
#
# Expected outcome:
# - Should find optimal hyperparameters for consistently solving CartPole
# - Typical best performance: ~200 reward with stable learning
# - Should complete in 50-100 trials depending on pruning efficiency

# Base experiment configuration to modify
base_config: "configs/experiments/ppo_cartpole.yaml"

# Sweep metadata
sweep:
  name: "ppo_cartpole_hyperopt"
  study_name: "ppo_cartpole_sweep_v1"
  storage: "sqlite:///experiments/sweeps/ppo_cartpole.db"  # Local SQLite storage
  direction: "maximize"  # Maximize evaluation reward
  
  # Optuna sampler configuration
  sampler:
    type: "TPE"  # Tree-structured Parzen Estimator (recommended)
    # Alternative samplers: "Random", "CmaEs", "GP" (Gaussian Process)
    n_startup_trials: 10  # Random trials before TPE kicks in
    n_ei_candidates: 24   # Number of candidates for expected improvement
    
  # Pruning configuration (early stopping of poor trials)
  pruner:
    type: "MedianPruner"  # Stop trials performing worse than median
    n_startup_trials: 5   # Don't prune first 5 trials
    n_warmup_steps: 5000  # Don't prune before 5k timesteps
    interval_steps: 2500  # Check for pruning every 2.5k steps

# Hyperparameters to optimize
parameters:
  # Algorithm hyperparameters
  algorithm.lr:
    type: "log_uniform" 
    low: 1e-5
    high: 1e-2
    
  algorithm.clip_ratio:
    type: "uniform"
    low: 0.1
    high: 0.4
    
  algorithm.entropy_coef:
    type: "log_uniform"
    low: 1e-4
    high: 1e-1
    
  algorithm.value_coef:
    type: "uniform" 
    low: 0.1
    high: 1.0
    
  algorithm.ppo_epochs:
    type: "int"
    low: 2
    high: 10
    
  algorithm.minibatch_size:
    type: "categorical"
    choices: [32, 64, 128, 256]
    
  algorithm.max_grad_norm:
    type: "uniform"
    low: 0.3
    high: 1.0
    
  # Buffer configuration
  buffer.capacity:
    type: "categorical" 
    choices: [1024, 2048, 4096]
    
  buffer.gae_lambda:
    type: "uniform"
    low: 0.9
    high: 0.99
    
  # Network architecture
  network.actor.hidden_dims:
    type: "categorical"
    choices: [[32, 32], [64, 64], [128, 128], [64, 32], [128, 64]]
    
  network.critic.hidden_dims:
    type: "categorical" 
    choices: [[32, 32], [64, 64], [128, 128], [64, 32], [128, 64]]

# Fixed overrides (same for all trials)
overrides:
  # Reduce training time for hyperparameter search
  training.total_timesteps: 50000
  training.eval_frequency: 5000
  training.num_eval_episodes: 5
  
  # Disable heavy logging during sweep
  logging.tensorboard: false
  logging.wandb_enabled: false
  logging.terminal: false  # Reduce terminal spam
  
  # Ensure reproducibility within trials
  experiment.seed: 42

# Sweep execution configuration
execution:
  n_trials: 100  # Maximum number of trials to run
  timeout: 7200  # Maximum time in seconds (2 hours)
  n_jobs: 1      # Number of parallel jobs (1 for single machine)
  
  # Trial timeout (stop individual trials that take too long)
  trial_timeout: 600  # 10 minutes per trial
  
  # Resource management
  gpu_per_trial: 0    # Use CPU for CartPole (faster for small problems)
  memory_per_trial: "2GB"  # Memory limit per trial

# Objective function configuration  
objective:
  # Primary metric to optimize
  metric: "eval_return_mean"
  
  # Multi-objective optimization (optional)
  # secondary_metrics:
  #   - name: "training_stability" 
  #     weight: 0.1
  #   - name: "sample_efficiency"
  #     weight: 0.1
  
  # Constraints (trials violating these are pruned)
  constraints:
    - metric: "eval_return_mean"
      condition: ">"
      value: 50  # Must achieve at least 50 reward to continue
      
# Analysis configuration
analysis:
  # Generate these plots after sweep completion
  plots:
    - "optimization_history"
    - "param_importances" 
    - "parallel_coordinate"
    - "slice_plot"
    
  # Export best trials
  export_best_n: 10
  
  # Hyperparameter importance analysis
  importance_evaluator: "fanova"  # or "permutation"

# Advanced features
advanced:
  # Resume behavior
  load_if_exists: true  # Resume existing study if found
  
  # Trial restart on failure
  max_trial_failures: 3
  
  # Custom trial naming
  trial_name_template: "ppo_cartpole_{trial_number:03d}"
  
  # Experiment organization
  experiment_root: "experiments/sweeps"
  keep_all_trials: false  # Only keep best trials to save disk space
  
# Expected results and guidelines
expected_results:
  # Performance benchmarks
  baseline_random: 22      # Random policy average
  baseline_default: 150    # Default hyperparameters from base config
  target_performance: 195  # CartPole solved threshold
  optimal_performance: 200 # Maximum possible
  
  # Efficiency expectations
  trials_to_good_solution: 30   # Should find good params within 30 trials
  trials_to_optimal: 60         # Should find near-optimal within 60 trials
  pruned_trial_percentage: 70   # ~70% of trials should be pruned early
  
  # Common good parameter ranges (for reference)
  good_lr_range: [3e-4, 1e-3]
  good_clip_range: [0.15, 0.25] 
  good_entropy_range: [0.01, 0.02]

# Troubleshooting tips
troubleshooting:
  poor_optimization:
    - "Check if pruner is too aggressive (increase n_warmup_steps)"
    - "Try different sampler (CmaEs for continuous, Random for debug)"
    - "Increase n_startup_trials if TPE starts too early"
    
  slow_convergence:
    - "Reduce trial_timeout if trials are hanging"
    - "Check if objective metric is being reported correctly"
    - "Consider reducing total_timesteps for faster trials"
    
  memory_issues:
    - "Reduce n_jobs for parallel execution"
    - "Set keep_all_trials: false"
    - "Lower memory_per_trial limit"