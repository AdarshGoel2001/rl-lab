experiment:
  name: "acrobot_random_baseline"
  seed: 42
  device: "cpu"
  
algorithm:
  name: "random"
  
environment:
  name: "Acrobot-v1"
  wrapper: "gym"
  normalize_obs: false
  normalize_reward: false

network:
  # Random agent doesn't use networks, but config validation requires this
  actor:
    type: "actor_mlp"
    hidden_dims: [64, 64]
    activation: "tanh"
    output_activation: "linear"
  critic:
    type: "critic_mlp"
    hidden_dims: [64, 64]
    activation: "tanh"
    output_activation: "linear"

buffer:
  type: "trajectory"
  capacity: 2048
  batch_size: 2048
  gamma: 0.99
  gae_lambda: 0.95
  compute_returns: true
  normalize_advantages: true
  
training:
  total_timesteps: 10000
  eval_frequency: 2000
  checkpoint_frequency: 10000
  num_eval_episodes: 10
  
logging:
  terminal: true
  tensorboard: false
  wandb:
    enabled: false