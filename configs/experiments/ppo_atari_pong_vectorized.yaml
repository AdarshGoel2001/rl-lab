# PPO Atari Pong with Vectorized Environments and Composable Transforms
#
# This configuration demonstrates the new composable transform system with
# proper vectorized environment support for Atari games.
#
# Key improvements over the old system:
# - Per-environment transform state isolation
# - Mix-and-match transform composition
# - BHWC observation format support
# - Clean separation of concerns
# - Easy configuration-driven experimentation

experiment:
  name: "ppo_atari_pong_vectorized"
  seed: 42
  device: "auto"

algorithm:
  name: "ppo"
  
  # PPO hyperparameters optimized for Atari
  lr: 2.5e-4
  lr_schedule: "linear"
  clip_ratio: 0.1
  value_coef: 0.5
  entropy_coef: 0.01
  
  # Training configuration
  ppo_epochs: 4
  minibatch_size: 256
  max_grad_norm: 0.5
  
  # Advantage computation
  normalize_advantages: true
  clip_value_loss: true

environment:
  name: "ALE/Pong-v5"
  wrapper: "vectorized_gym"          # Use new vectorized wrapper
  num_envs: 8                        # 8 parallel environments
  vectorization: "auto"              # Auto-select sync/async
  
  # Composable transform pipeline
  observation_transforms:
    - type: "atari_vision"           # Expands to full Atari preprocessing
  
  # Environment settings
  normalize_obs: false               # Handled by transforms
  normalize_reward: false
  env_kwargs:
    full_action_space: false
    repeat_action_probability: 0.25

# Single environment for evaluation (clean metrics)
evaluation:
  name: "ALE/Pong-v5"
  wrapper: "gym"                     # Single environment
  
  # Same transforms as training for consistency
  observation_transforms:
    - type: "atari_vision"
  
  normalize_obs: false
  normalize_reward: false
  env_kwargs:
    full_action_space: false
    repeat_action_probability: 0.25

network:
  # Actor network - Nature CNN handles BHWC input automatically
  actor:
    type: "nature_cnn"
    channels: [32, 64, 64]
    hidden_dim: 512
    activation: "relu"
    
  # Critic network - same architecture as actor
  critic:
    type: "nature_cnn"
    channels: [32, 64, 64]
    hidden_dim: 512
    activation: "relu"

buffer:
  type: "trajectory"
  capacity: 128                      # Steps per environment
  batch_size: 1024                   # 8 envs * 128 steps
  
  # GAE parameters
  gamma: 0.99
  gae_lambda: 0.95
  compute_returns: true
  normalize_advantages: true

training:
  total_timesteps: 10000000          # 10M timesteps
  eval_frequency: 100000             # Every 100k steps
  checkpoint_frequency: 500000       # Every 500k steps
  num_eval_episodes: 10              # Clean evaluation episodes
  
  # Early stopping
  early_stopping: true
  target_reward: 15.0                # Strong Pong performance
  patience: 5

logging:
  terminal: true
  tensorboard: true
  log_frequency: 10000
  
  wandb_enabled: false               # Disable for testing
  wandb:
    project: "rl-lab-atari-vectorized"
    tags: ["ppo", "atari", "pong", "vectorized", "transforms"]
    notes: "PPO on Atari Pong with composable transforms and vectorized environments"

# Transform system benefits demonstrated:
transform_system_features:
  isolation: "Per-environment transform state (frame stacking isolated)"
  composition: "Mix and match transforms via configuration"
  formats: "BHWC observations work seamlessly with networks"
  presets: "atari_vision preset expands to full preprocessing"
  vectorization: "Proper parallel environment support"
  debugging: "Each component testable independently"

# Example alternative transform configurations
alternative_transforms:
  # Minimal preprocessing
  minimal:
    - type: "to_grayscale"
    - type: "resize"
      height: 84
      width: 84
    - type: "scale_to_float"
  
  # Custom Atari with different frame count
  custom_atari:
    - type: "atari_preprocessing"
      noop_max: 30
      frame_skip: 4
    - type: "to_grayscale"
    - type: "resize"
      height: 84
      width: 84
    - type: "scale_to_float"
    - type: "frame_stack"
      n_frames: 8                    # 8 frames instead of 4
  
  # High resolution
  high_res:
    - type: "atari_preprocessing"
    - type: "to_grayscale"
    - type: "resize"
      height: 168                    # 2x resolution
      width: 168
    - type: "scale_to_float"
    - type: "frame_stack"
      n_frames: 4

# Expected observation shapes after transforms
observation_shapes:
  after_preprocessing: "[210, 160, 3]"     # Raw Atari frame
  after_grayscale: "[210, 160]"            # Grayscale conversion
  after_resize: "[84, 84]"                 # Resized to standard
  after_scale: "[84, 84]"                  # Float32 [0, 1] range
  after_frame_stack: "[84, 84, 4]"         # 4 frames stacked
  network_input: "[batch, 84, 84, 4]"      # BHWC format to networks

# Performance expectations
expected_performance:
  training_time_hours: 3.5               # Slightly faster with optimized pipeline
  memory_efficiency: "Better than old system"
  debugging_ease: "Much easier to debug individual transforms"
  configuration_flexibility: "High - easy to experiment with different pipelines"
